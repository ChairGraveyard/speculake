
\section{Discussion}

\subsection{Resilience of \speculake}
%Spectre works to use a cache side-channel to leak information from a process. As
%such defenses to Spectre work to limit the information available to a
%speculatively executing program. 
%
\subsubsection{Spectre Versions}
In this work we have implemented applications making use of the speculative
primitive in Spectre version 2, however the speculative primitive is not 
unique to this varaint. The \speculake model can be applied more broadly
across the spectrum of speculative functionality to hide malicious computation.

For example an attacker could construct a series of direct branches with 
contradictory conditions such that the resulting code section can never 
be on a real world execution path.
This, however does not prevent the section from being speculated. An 
attacker may be able to hide a jump to a speculative entry point in 
this section and train the branch predictor to take this path. 

Alternatively, recent variants of Spectre version 1 could be used to
redirect control flow in speculative overflow style attacks~\cite{}. 
Using this technique speculative gadgets could be executed
based on attacker controlled input. 

Similarly we theorize that speculative-store-bypass could be used to
redirect control flow when the mis-speculated load is that of an indirect
branch target or function pointer. Again the speculative primitive could 
be employed to execute speculative gadgets. 

These alternatives create an even larger attack area for a potential 
reverse engineer as the attacker can pivot between them with minimal alterations. 

\subsubsection{Gadget Location}
The benefits of \speculake rely on the computation performed in the
speculative world being well hidden. To this end we have verified 
certain requirements about the locations that a speculative gadget can 
be placed within a binary. 

First and foremost the gadget must be in the instruction cache. 
This does not require that the actual instructions ever run,
 only that they are in cache. We have 
found that this is not a large barrier to overcome as Intel 
processors aggressively prefetch cache pages~\cite{measuring-cache}
and simple access patterns could be established to ensure
that the required block(s) are accessible. 

We have also confirmed that all speculative code in the payload must be
stored in executable pages, and that it cannot be stored in non-executable data
sections. This is somewhat surprising, given the nature of the Meltdown
vulnerability that enabled speculative execution past page faults. However, in
the case of Meltdown, the speculative computation still occurs in pages marked
as executable.

%We suspect that this is again due to caching. The processor has no
%reason to cache instructions stored in the data section in the instruction
%cache. If a trigger trains the branch predictor to jump to an address in the
%payload's data section, the payload will not be able to fetch the instructions
%into the execution pipeline. 


\subsubsection{Hypervisors}
For virtual environments that provide guests significant periods of access to
hardware resources, \speculake is viable in certain configurations. 
This result is specific to Spectre version 2 as it relies on 
the indirect branch predictor effecting the branches in either the host 
or guest environment. We have found that the hypercall context switch from 
guest to host is light enough that a trigger program running in a guest
can effect the branch predictor in a host on the same CPU core. This is not
true in the alternate configuration where the trigger runs on the host as the 
hypercall transition seems to be more substantial. This implies, and we have verified,
that guest-to-guest indirect branch predictor interference, and the current
\speculake implementation, will not work across disparate virtual environments.

\subsection{Defenses}
We now address possible defenses to detecting and reverse engineering malware that uses
\speculake. 
\subsubsection{Implemented Mitigations}
Multiple mitigation have been implemented in production and consumer environments
already, stretching from compiler patches to micro-code updates.

IBPB - IBPB is used when transitioning to a new secure address space allowing a
program to ensure that earlier code's behavior does not effect its branch prediction.
However, this does not prevent a willing payload program from intentionally omitting
IBPB protections.

STIBP - As discussed in section~\ref{sssec:hyperthread} Single Thread Indirect Branch Predictors
prevent sibling threads from interacting via the Indirect Branch Predictor~\cite{}.
However, this does not prevent coresident processes from cooperating, which is
guaranteed to eventually occur in most modern operating systems.

IBRS - Prevents code from less privileged prediction modes from effecting predicted
addresses, specifically used for portecting the kernel. This does not
prevent speculative execution in a willing payload program in a less privileged
speculation mode.

Retpoline - Using speculation to prevent speculation, retpoline is a construction
used to prevent arbitrary indirect jumps that can be included inline by a compiler
or patched into a binary~\cite{}. While this successfully thwarts indirect branch prediction
tampering it incurs a siginificant performance penalty when applied globally to all
indirect branches~\cite{}.

\subsubsection{Malware Detection}
\label{subsubsec:malware}
Like Spectre, \speculake relies on a cache side-channel to transfer
information from the speculative world to the real world. Since the payload
program must at least occasionally watch this side channel, it offers a
potential method for detecting \speculake malware.

Analysts could search for telltale signs of cache inference behavior, such as
the use of \texttt{clflush} instructions or reading cycle timings. However,
while this would allow detection of \speculake malware, it does not directly
help in reverse engineering the malware's behavior. We also note that our
implementation of \speculake used the \texttt{Flush+Reload} cache side channel
method, but other methods (such as \texttt{Prime+Probe}) could be used in its
place.

In addition, the malware can also employ more subtle and less direct methods
of measuring what is in the cache. For example, creating race conditions between
multiple threads that results in different behaviors depending on which threads
values are cached.

Finally, \speculake could also use another side channel method that
avoids the cache
to exfiltrate information from the speculative gadgets, such as the branch
predictor itself~\cite{evtyushkin2018branchscope}, memory bandwidth, power
utilization, or contention over other shared resources. While cache 
channels tend to have the highest throughput, they are not the only 
resource that must be monitored to detect or prevent these types of attacks. 

\paragraph{Red-Pills}
Hardware minutia have also been used to identify and fingerprint execution
environments---in malware this is known as a red-pill~\cite{red-pill} and is
typically used by malware to detect when it is under emulation or a debugging
environment~\cite{lindorfer2011detecting, balzarotti2010efficient,
paleari2009fistful} attempting to circumvent malware detectors. To address
red-pills, systems often employ measures to detect them. ``Bare-metal''
emulation of malware~\cite{kirat2011barebox}, methods to determine if malware is
performing red-pill checks to avoid emulation
environments~\cite{kirat2014barecloud}, and symbolic execution can be used to
combat red-pills by finding environmental triggers in malicious
binaries~\cite{schwartz2010all}. Similar sand-boxing techniques may be applied
to detect \speculake malware.

Unlike red-pills, \speculake complicates analysis and impedes malware detectors
with the use a trigger program and speculative execution. The use of a separate
and seemingly benign trigger program influenced by the adversary enables the
\speculake malware to limit detection by acting benign until triggered to
influence the branch predictor (while still appearing innocuous). 

Additionally, as an \speculake attack is carried out via speculative execution,
the instructions executed and speculative state are not committed to by the
processor and are thus obscured from analysts. Similarly, symbolic execution
will fail to find the speculative gadgets as they are never on the (committed)
execution pathway. 

Furthermore, direct analysis such as with break-points (and other
debugging techniques) will not aid in unravelling \speculake malware as
break-points interrupt the control flow of a program and prevent speculative
execution. This allows \speculake to effectively act as a red-pill while
avoiding detection as such. Suggesting that significant work would be required
to adapt current red-pill detectors to detect \speculake malware.

%While the notion of simply adapting current defenses to recognize this new
%strain of malware may be simplest, we caution that the methods introduced by
%\speculake are very general and can be accomplished in numerous ways and simply
%attempting to recognize one method will undoubtedly be circumvented by future
%generations of this malware.

\subsubsection{Hardware-level defenses}
Ultimately, speculative execution vulnerabilities stem from problems in
hardware, and are best fixed there. However, we note that fixing problems in
order to prevent Spectre may not necessarily prevent \speculake malware. In Spectre, an application is
coerced against its will to mis-speculate branches, but in \speculake, the
application willfully encourages the mis-speculation. Thus, some solutions may
defend against Spectre, but not \speculake.


One such solution is a new \texttt{specfence} instruction, that prohibits the
CPU from speculating past. This instruction would require that loads and stores after
the instruction must wait (and cannot be pre-fetched) until the
\texttt{specfence} instruction has retired. We note this is distinct from the
\texttt{mfence} instruction that serializes memory transactions. Speculative
reads and out-of-order execution can still occur past an \texttt{mfence}, and
the instruction does not serialize the instruction
stream~\cite{intel-software-guide}.

One way to achieve a \texttt{specfence} pseudo-instruction is to fill the ROB
with enough instructions that the CPU cannot speculate past it. We find that the
\texttt{rep} prefix for string operations is able to do this if it is set to 
repeat more than 96 times, presumably as it issues $2*96$ $\mu$-ops, and fills the
ROB~\cite{intel-instruction-tables}.

However effective such an instruction may be against Spectre, it is not a
defense against \speculake. A malicious \speculake malware author would simply
not include such an instruction in either their payload or trigger programs.
% Could add:
%This demonstrates the versatility of speculative execution in general. While
%defenses against Spectre are needed, a more general purpose solution to
%speculative execution as a whole is necessary to address the wide range of its
%capabilities.


\paragraph{Operating System Defense}
Hardware could also provide the operating system with a privileged instruction
that gives it more control over the interaction between programs. For example,
the OS could use a privileged instruction to copy out the Branch History Buffer
(BHB) state when it context switches between processes, restoring it when the
process is restored. This would prevent cross-process interactions with the
branch predictor, and prevent multi-process \speculake malware. However, it does
not prevent a single-process \speculake, and it does not fully address the
Spectre vulnerability.


%\subsubsection{Cache Poisoning}
%As mentioned in Section~\ref{subsubsec:malware} a vital component of \speculake
%is the ability to perform cache timings. Any mechanism that modifies the cache
%can affect the success of \speculake-like attacks.
%
%Drastic methods such as completely poisoning the cache will hinder this attack
%while also forcing almost all loads to result in a cache miss, effectively
%nullifying the point of cache.
%
%However, more conservative methods such as randomly loading values into cache
%can have a negative affect on \speculake-like attacks (causing the cache timing
%to predict incorrect values) while not having too detrimental of an affect on
%programs as a whole.
%
%In response to this method of defense \speculake-like attacks can modify the
%number of iterations and confidence thresholds necessary to determine a value.
%As mentioned in Section~\ref{subsec:impl-turing} our experiments found that it
%was only necessary to perform 50 iterations of our \texttt{target\_fn} in order
%to gain 80\% confidence in the value returned. While only 50 iterations are
%necessary, increasing this value to higher levels can lead to a significantly
%higher confidence with very little performance detriment (especially in the
%case of AES decryption).


\subsection{Future Work}
\label{subsec:future-work}

This work demonstrates a general model for hiding execution in 
the speculative world and examines the implications and limitations on 
Intel processors. Given the wide-spread nature of the Spectre vulnerability 
and the ubiquity of cache side-channels we believe that this work can 
be directly extended to AMD, ARM, and other processors making use of
speculative branch prediction.

\subsubsection{Multiple Triggers}
To create further difficulties for an analyst, or to further target the
execution environment it is possible to have the payload program test a series
of separate jump patterns. Instead of requiring only a single trigger program,
the payload could require multiple trigger programs to be running
simultaneously, or in a particular order.

This could allow fine-grained targeting of malware. For instance, the attacker
could distribute trigger programs through different channels to target different sets
of victims, and have the ultimate payload only operate at the intersection of
these groups. As an example, one trigger program could be distributed to a
particular country (e.g. Iran), and another to a particular device globally
(centrifuge controllers), resulting in the malicious payload (Stuxnet) only
being revealed and executed on the intersection of these two groups.


\smallskip

Alternatively multiple triggers could be used make individual state changes in
the payload program, and write in data from a local, or (as demonstrated in
Section~\ref{subsec:openssl}) remote processes. For example, a payload program
can check a series of three distinct jump patterns corresponding to three
different triggers. If the first trigger is detected the payload shifts in a 1
to the state; if the second is detected it shifts in a 0. If the third trigger
is detected it discontinues listening to the three triggers and executes the
data shifted into the state.
This could be a direct form of \speculake using emulation and
decryption or more traditional malicious behavior. Using this method a payload
program can be distributed without the encrypted data section all together,
instead having the data written into the process at run-time without ever
connecting out to any other resource.

\subsubsection{Benign Triggers}
We have demonstrated that a using \allowbreak OpenSSL as a benign trigger allows for
\speculake payloads to be triggered remotely, and discussed the minimum
requirements for identifying a benign trigger. However, we have not classified
typical system resources that might be used as benign triggers. This is a
promising direction for future investigation as various system libraries present
juicy targets for trigger design. For example, if a sufficient series of jumps
is found to exist in the TCP stack implemented in the UNIX kernel (i.e. in the
TCP Checksum library) an attacker could reasonably trigger a \speculake payload
remotely, from a spoofed IP address. This attack would rely on a payload
defeating KASLR, however, this has been demonstrated to be
feasible~\cite{gruss2017kaslr,evtyushkin2016jump}.

%% Approximate Computing 
\subsubsection{Approximate Computing}
Approximate Computing prioritizes the computation of quick results that are
potentially incorrect. This form of computation often leverages some type of
machine learning to determine how well individual results fit with a crowd of
approximately computed results. As mentioned in Section~\ref{subsec:impl-turing}
occasionally values necessary for computation in the speculative world are not
in cache and thus must be speculated themselves. In this situation error
correcting codes are useless given that the mistake is not a mutation of the
correct input, but rather a guess at what the input might be. The mechanisms
used in approximate computing may be beneficial here, allowing computation to
run speculatively and have an outer process that is tolerant of errors or
mis-steps by the speculative world.



\subsubsection{Alternative Applications}
We have proposed the \speculake model as a new malware threat, however, this
model of hidden computation applies more broadly. As of now there are no ways of
debugging speculative computation, meaning that the computation done there is
effectively isolated and difficult to extract by third-parties. While not a true
trusted execution environment, it could be used like one, offering potential
uses in Digitial Rights Management (DRM), and whitebox cryptography.



%%%%%%%%%%%%%%
