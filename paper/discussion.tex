
\section{Discussion}

\if0
%Cutting this for now. We sort of cover it in the Turing section(s)

\subsection{Resilience of \speculake}
%Spectre works to use a cache side-channel to leak information from a process. As
%such defenses to Spectre work to limit the information available to a
%speculatively executing program. 

\subsubsection{Gadget Location}
The benefits of \speculake rely on the computation performed in the
speculative world being well hidden. To this end we have verified 
certain requirements about the locations that a speculative gadget can 
be placed within a binary. 

First and foremost the gadget must be in the instruction cache. 
This does not require that the actual instructions ever run,
 only that they are in cache. We have 
found that this is not a large barrier to overcome as Intel 
processors aggressively prefetch cache pages~\cite{measuring-cache}
and simple access patterns could be established to ensure
that the required block(s) are accessible. 

We have also confirmed that all speculative code in the payload must be
stored in executable pages, and that it cannot be stored in non-executable data
sections. This is somewhat surprising, given the nature of the Meltdown
vulnerability that enabled speculative execution past page faults. However, in
the case of Meltdown, the speculative computation still occurs in pages marked
as executable.
\fi


%We suspect that this is again due to caching. The processor has no
%reason to cache instructions stored in the data section in the instruction
%cache. If a trigger trains the branch predictor to jump to an address in the
%payload's data section, the payload will not be able to fetch the instructions
%into the execution pipeline. 


\subsection{Defenses}
We now address possible defenses to detecting and reverse engineering malware
that uses \speculake. 


\subsubsection{Implemented Mitigations}
Multiple patches and micro-code updates have been developed to mitigate Spectre
vulnerabilities, however, none of these entirely prevent \speculake malware from
working, as they are generally not designed to protect programs that willingly
use Spectre against themselves.

\paragraph{Indirect Branch Predictor Barrier}IBPB is used when transitioning to
a new address space, allowing a program to ensure that earlier code's behavior
does not effect its branch prediction. IBPB requires CPU and operating system
support. However, we observe on Linux that processes running under the same user
group do not receive IBPB protection, enabling \speculake when the trigger and
payload run under the same group. Furthermore, IBPB does not prevent the
speculative buffer overflow variant of \speculake described in
Section~\ref{subsec:spec-buffer-overflow}.

%However, this does not prevent a willing payload program from intentionally omitting
%IBPB protections.

\paragraph{Single Thread Indirect Branch Predictors}STIBP prevents sibling
hyperthreads from interacting via the indirect branch predictor. However, this
does not prevent co-resident processes from cooperating when they run on the
same logical core.

\paragraph{Indirect Branch Restricted Speculation}IBRS prevents code in less
privileged prediction modes from influencing indirect branch prediction in
higher privileges (e.g. the kernel). This does not
prevent speculative execution in a willing payload program in a less privileged
speculation mode.

\paragraph{Retpoline}is a software mitigation that replaces indirect jumps with
a special call/overflow/return sequence, controlling where the CPU will
speculate the indirect branch to a contained (and benign)
section~\cite{retpoline}. However, this defense is opt-in which \speculake
binaries could simply choose to not use, or alternatively use the unaffected
speculative buffer overflow variant.

\subsubsection{Malware Detection}
\label{subsubsec:malware}
While not a primary goal of \speculake, we consider the ability of \speculake
malware to hide from detection.

When using the cache side channel variant of \speculake, the payload program
must at least occasionally watch this side channel, offering a potential method
for detecting \speculake malware. Analysts could search for telltale signs of
cache inference behavior, such as the use of \texttt{clflush} instructions or
reading cycle timings. At the cost of performance, \speculake could choose to
use a more subtle cache side channel that does not require this, such as
\texttt{Prime+Probe}, or by exploiting race conditions between multiple threads
to allow the speculative world to influence the behavior of the real world.

\speculake could also use another side channel method that avoids the cache to
exfiltrate information from the speculative gadgets, such as the branch
predictor itself~\cite{evtyushkin2018branchscope}, memory bandwidth, power
utilization, or contention over other shared
resources~\cite{kiriansky2018speculative}. While cache channels tend to have the
highest throughput, they are not the only resource that must be monitored to
detect or prevent these types of attacks. 

%\paragraph{Red-Pills}
%Hardware minutia have also been used to identify and fingerprint execution
%environments---in malware this is known as a red-pill~\cite{red-pill} and is
%typically used by malware to detect when it is under emulation or a debugging
%environment~\cite{lindorfer2011detecting, balzarotti2010efficient,
%paleari2009fistful} attempting to circumvent malware detectors. To address
%red-pills, systems often employ measures to detect them.
\paragraph{Anti-Virus Detectors}
We verified that modern Anti-Virus technologies were unable to detect
and flag \speculake malware. We used ClamAV, BitDefender and rkhunter, which
mainly rely on signature and string based detection. BitDefender does feature
support for unpacking or extracting malware, though appears to simply try
unpacking using several known packers and encoding formats~\cite{BitDefender}.
Thus, it is not surprising that these tools cannot detect
\speculake.

\paragraph{Bare Metal}
Modern malware often uses hardware minutia to identify and fingerprint execution
environments in order to detect when it is under debugging or
inspection~\cite{lindorfer2011detecting,balzarotti2010efficient,paleari2009fistful}.
To prevent such identification, analyzers often employ ``bare metal''
execution~\cite{kirat2011barebox}, running the malware on dedicated hardware
that allows introspection and observation of the system without interfering with
its normal operation. This prevents malware from using so-called ``red pill''
checks to observe that it is under test (and hide its malicious
behavior)~\cite{kirat2014barecloud}. However, to the best of our knowledge, no
publicly available bare-metal environments allow introspection on the
speculative state of the CPU, making it difficult to analyze \speculake malware.
However, such environments could be useful for observing the behavior of
\speculake malware in the presence of its trigger if available, as modifications
in the real world could be easily tracked.

%but this presumably would not be
%present in such a context.

Symbolic execution has also been used to find
environmental red pill checks~\cite{schwartz2010all}. However, such analysis
would be ineffective against \speculake, as symbolic execution does not reason
about speculative paths and how they might influence a program.

%Unlike red-pills, \speculake complicates analysis and impedes malware detectors
%with the use a trigger program and speculative execution. The use of a separate
%and seemingly benign trigger program influenced by the adversary enables the
%\speculake malware to limit detection by acting benign until triggered to
%influence the branch predictor (while still appearing innocuous). 
%
%Additionally, as an \speculake attack is carried out via speculative execution,
%the instructions executed and speculative state are not committed to by the
%processor and are thus obscured from analysts. Similarly, symbolic execution
%will fail to find the speculative gadgets as they are never on the (committed)
%execution pathway. 
%

%Furthermore, direct analysis using break-points (and other
%debugging techniques) will not aid in unravelling \speculake malware as
%break-points interrupt the control flow of a program and prevent speculative
%execution. This allows \speculake to effectively act as a red-pill while
%avoiding detection as such. Suggesting that significant work would be required
%to adapt current red-pill detectors to detect \speculake malware.

%While the notion of simply adapting current defenses to recognize this new
%strain of malware may be simplest, we caution that the methods introduced by
%\speculake are very general and can be accomplished in numerous ways and simply
%attempting to recognize one method will undoubtedly be circumvented by future
%generations of this malware.


\if0
\subsubsection{Hardware-level defenses}
Ultimately, speculative execution vulnerabilities stem from problems in
hardware, and are best fixed there. However, we note that fixing problems in
order to prevent Spectre may not necessarily prevent \speculake malware. In
Spectre, an application is coerced against its will to mis-speculate branches,
but in \speculake, the application willfully encourages the mis-speculation.
Thus, some solutions may defend against Spectre, but not \speculake.


One such solution is a new \texttt{specfence} instruction, that prohibits the
CPU from speculating past. This instruction would require that loads and stores
after the instruction must wait (and cannot be pre-fetched) until the
\texttt{specfence} instruction has retired. We note this is distinct from the
\texttt{mfence} instruction that serializes memory transactions. Speculative
reads and out-of-order execution can still occur past an \texttt{mfence}, and
the instruction does not serialize the instruction
stream~\cite{intel-software-guide}.

One way to achieve a \texttt{specfence} pseudo-instruction is to fill the ROB
with enough instructions that the CPU cannot speculate past it. We find that the
\texttt{rep} prefix for string operations is able to do this if it is set to
repeat more than 96 times, presumably as it issues $2*96$ $\mu$-ops, and fills
the ROB~\cite{intel-instruction-tables}.

However effective such an instruction may be against Spectre, it is not a
defense against \speculake. A malicious \speculake malware author would simply
not include such an instruction in either their payload or trigger programs.
% Could add:
%This demonstrates the versatility of speculative execution in general. While
%defenses against Spectre are needed, a more general purpose solution to
%speculative execution as a whole is necessary to address the wide range of its
%capabilities.
\fi

\subsubsection{Reverse-engineering triggers}
For program-based triggers, an analyst could attempt to find the trigger program
by examining the execution path of the payload program, and locating a common
indirect jump pattern between payload and potential triggers. Since both
programs must share a common indirect jump pattern to interact via the indirect
branch predictor, there must be some overlap which is unlikely to occur randomly
between two programs.

We note that while the analyst may learn the execution path (and thus true
indirect jump pattern) of the payload program, they may not be able to capture
every potential execution path in all potential triggers. For example, in the
OpenSSL trigger, the analyst may not have captured all potential indirect jump
patterns, as doing so would require exhaustively connecting to OpenSSL with
different cipher suites, extensions, and failed handshakes. However, the analyst
can still make a list of indirect jump locations in a suspected trigger program,
comparing these to the jumps taken by the payload. If there is significant
overlap, the analyst could spend time to discover what inputs to the trigger
program produce similar indirect jump patterns, thus discovering the trigger.

\speculake malware could attempt to thwart this analysis by using decoy indirect
jumps that do not correspond with the trigger, but potentially correspond with
other (non-trigger) binaries. In addition, this analysis method is ineffective
at inspecting the speculative buffer overflow variant described in
Section~\ref{subsec:spec-buffer-overflow}, as it does not use a separate trigger
program.

Alternatively an analyst may attempt to identify sections of the program or dead 
code that will be used to access the probe array and thereby find the speculative 
gadgets. However, identifying sections of memory that will access the probe 
array is equivalent to the ``Must Alias'' or ``Points-To Problem'' which has been 
proven undecidable without significant 
restrictions~\cite{ramalingam1994undecidability,landi1992undecidability}.

%
% Theorem 1. ([7, 10]) Single procedural flow-sensitive points-
% to analysis with dynamic memory and non-scalar variables
% is undecidable.
% Our first result improves the above undecidability result
% to
% Theorem 2. Single procedural flow-sensitive points-to
% analysis with dynamic memory is undecidable, even when
% only scalar variables are allowed.
%

\subsection{Future Work}
\label{subsec:future-work}

\speculake demonstrates a general model for hiding execution in 
the speculative world and examines the implications and limitations on
modern processors. Given the wide-spread nature of the Spectre vulnerability 
and the ubiquity of side-channels, we believe that this work can 
be directly extended to other architectures, such as ARM, and other processors
making use of speculative branch prediction.

\subsubsection{Multiple Triggers}
To create further difficulties for an analyst, or to further target the
execution environment, it is possible to have the payload program to combine
multiple triggers. Instead of requiring only a single trigger program, the
payload could require multiple trigger programs to be running simultaneously, or
in a particular order. Alternatively, the payload could combine trigger programs
with input triggers, forcing an analyst to understand multiple variants
simultaneously.

This could allow fine-grained targeting of malware. For instance, the attacker
could distribute trigger programs through different channels to target different
sets of victims, and have the ultimate payload only operate at the intersection
of these groups. As an example, one trigger program could be distributed to a
particular country (e.g. Iran), and another to a particular device globally
(centrifuge controllers), resulting in the malicious payload (Stuxnet) only
being revealed and executed on the intersection of these two groups.


\smallskip

Alternatively multiple triggers could be used make individual state changes in
the payload program, and write in data from a local, or (as described in
Section~\ref{subsec:openssl}) remote processes. For instance, triggers could be
used to shift in data or an entire program for emulation.
%For example, a payload program
%can check a series of three distinct jump patterns corresponding to three
%different triggers. If the first trigger is detected the payload shifts in a 1
%to the state; if the second is detected it shifts in a 0. If the third trigger
%is detected it discontinues listening to the three triggers and executes the
%data shifted into the state.
%This could be a direct form of \speculake using emulation and
%decryption or more traditional malicious behavior. 
Using this method a payload program can be distributed without the encrypted
data section at all, instead having the data written into the process indirectly
at run-time without ever connecting out to any other resource.

%\subsubsection{Benign Triggers}
%We have demonstrated that a using \allowbreak OpenSSL as a benign trigger allows for
%\speculake payloads to be triggered remotely, and discussed the minimum
%requirements for identifying a benign trigger. However, we have not classified
%typical system resources that might be used as benign triggers. This is a
%promising direction for future investigation as various system libraries present
%juicy targets for trigger design. For example, if a sufficient series of jumps
%is found to exist in the TCP stack implemented in the UNIX kernel (i.e. in the
%TCP Checksum library) an attacker could reasonably trigger a \speculake payload
%remotely, from a spoofed IP address. This attack would rely on a payload
%defeating KASLR, however, this has been demonstrated to be
%feasible~\cite{gruss2017kaslr,evtyushkin2016jump}.

%% Approximate Computing 
%\subsubsection{Approximate Computing}
%Approximate Computing prioritizes the computation of quick results that are
%potentially incorrect. This form of computation often leverages some type of
%machine learning to determine how well individual results fit with a crowd of
%approximately computed results. As mentioned in Section~\ref{subsec:impl-turing}
%occasionally values necessary for computation in the speculative world are not
%in cache and thus must be speculated themselves. In this situation error
%correcting codes are useless given that the mistake is not a mutation of the
%correct input, but rather a guess at what the input might be. The mechanisms
%used in approximate computing may be beneficial here, allowing computation to
%run speculatively and have an outer process that is tolerant of errors or
%mis-steps by the speculative world.

\subsubsection{Virtual Machines}
Virtual environments could also be host to \speculake malware and triggers. For
instance, malware on one EC2 instance could potentially be triggered by a
trigger program on another seemingly unrelated instance. We have found that the
hypercall context switch from guest to host on VirtualBox is lightweight enough
that a trigger program running in a guest can activate a payload program running
in the host on the same CPU core. However, we have so far been unable to go in
the opposite direction, and similarly have yet to achieve guest-to-guest
interference. More work is needed to determine if such barriers are possible to
overcome, and if stronger isolation is needed in the virtual machine context.

%For virtual environments that provide guests significant periods of access to
%hardware resources, \speculake is viable in certain configurations. 
%This result is specific to Spectre 2 variant, as it relies on 
%the indirect branch predictor effecting the branches in either the host 
%or guest environment. We have found that the hypercall context switch from 
%guest to host is light enough that a trigger program running in a guest
%can effect the branch predictor in a host on the same CPU core. This is not
%true in the opposite direction (where the trigger runs on the host) as the 
%hypercall transition seems to be more substantial. While this implies 
%that guest-to-guest indirect branch predictor interference, and the current
%\speculake implementation, will not work across disparate virtual environments,
%strict resource isolation gives a stronger guarantee of non-interference. 



% \subsubsection{Alternative Applications}
% We have proposed the \speculake model as a new malware threat, however, this
% model of hidden computation could be applied more broadly. As of now there are
% no ways of debugging speculative computation, meaning that the computation done
% there is effectively isolated and difficult to extract by third-parties, even
% with physical or root access to the machine it operates on. While not a true
% trusted execution environment, it is possible that such an environment could be
% used as a limited trusted environment. This may have potential use in digital
% rights management (DRM), and whitebox cryptography applications.
% 



% benign malicious programs? Use _just_ openssl to do arbitrary computation
% speculatively. May not be able to leak arbitrary things, but could be easier
% to do arbitrary computations. syscalls? probably not...but maybe leak info from
% existing ones. Kind of a merge of \speculake and Spectre.


%%%%%%%%%%%%%%
