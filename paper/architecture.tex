

\section{Architecture}

\speculake malware is comprised of two independent programs: a payload program,
and a trigger program. Both are installed on the victim's computer (e.g. via
trojan, remote exploit, or phishing), and must run simultaneously on the same
physical CPU. We note that the constraint of running programs on the same CPU is
not a significant burden: \texttt{taskset} can be used to limit a process to a
core, or if not available, the attacker can simply run multiple copies of the
trigger or payload program to coerce the OS scheduler to assign a
payload/trigger pair to the same core. We note that this is not a strict
requirement for the attacker as most OS schedulers will use round robin
algorithms to assign tasks to processors---eventually the trigger and payload
will execute co-resident on a single core. 

At a high level, the trigger program performs a series of indirect jumps in a
loop, training the branch predictor to this pattern. Meanwhile, the
payload program performs a subset of this jump pattern, then forces the CPU to
speculate by stalling the resolution of an indirect branch via a slow memory
read. The CPU will (mistakenly) predict the jump to follow the pattern performed
by the trigger program, and speculatively execute that destination in the
payload program.


\subsection{Threat Model}

We assume a scenario where an adversary wishes to hide or obscure the behavior
of a malicious program (malware) from an analyst attempting to reverse engineer
it. We note this is distinct from the goals of evading malware detection, where
malware escapes classification by an anti-virus or other automated tool. While
we believe \speculake could also be used to make automated detection more
difficult, our main focus is on reverse engineer resistance, useful for evading
manual classification concerned with malware behavior. For anti-virus evasion,
we refer the reader to several existing techniques that are sufficient to defeat
existing anti-virus
systems~\cite{jana2012abusing,oberheide2009polypack,ropinjector,swinnen2014one,ugarte2015sok}.


We assume the adversary is able to install binaries on the target machine (e.g.
via a trojan or remote exploitation), and the analyst is attempting to determine
what the malware will do using traditional debugging tools. We assume the
analyst may be aware that speculative execution is used to obfuscate behavior,
but does not have special-purpose hardware that allows introspection of the
CPU's speculative state. This assumption is realistic, as modern processors do
not allow developers or other users to directly interact with proprietary CPU
optimizations and features.

We further assume that the malware has a specific trigger that the analyst is
not privy to, and the adversary can influence. In our examples, this
trigger is often behavior exhibited by some other (potentially benign) process
running on the same system as the malware. As the adversary is able to control
when such a trigger is deployed (potentially remotely), the analyst will not be
able to observe or force this trigger to happen at will. We emphasize that while
this may also be true for existing trigger-based malware, analysts can often
reverse engineer the trigger out of the malware, for example by observing
control flow within the malware and using adaptive
fuzzers~\cite{afl,stephens2016driller} to generate inputs that explore other
execution paths of the binary. In contrast, \speculake malware's trigger depends
on behavior in seemingly unrelated binaries, influencing malware behavior
through channels that are effectively invisible to the analyst. As with typical
malware, the analyst may attempt to reverse engineer the trigger to reveal the
malware's behavior, but we will show (in Section~\ref{subsec:nested-spec}) how
to defeat this type of analysis.

\subsection{Indirect jumps}


In \speculake, we cause the CPU to mis-speculate the destination of an indirect
branch in the payload program, causing it to speculatively execute 
instructions that are never truly executed. We term the destination where speculation begins
the \emph{speculative entry point}. \speculake uses indirect jumps to allow
speculative execution from \emph{any} instruction in the payload process'
address space. Because it can jump to any instruction, the malware analyst has a
difficult task in determining where a payload program's speculative entry point
is.

In fact, the location of this entry point is not determined by the payload
program, but rather the corresponding trigger program. This means that with only
the payload program, an analyst does not posses enough information to find the
speculative entry point.



Indirect branch predictors allow the CPU to predict the destination address of a
branch based solely off its source address and a brief history of previous
branch sources and destinations. While the inner-working details of modern CPU
branch predictors are proprietary, it is possible to reverse engineer parts of
their behavior, which we do for \speculake.

We observe that Intel CPUs consider three types of x86\_64 indirect branches:
\texttt{retq}, \texttt{callq *\%rax}, and \texttt{jmpq *\%rax}\footnote{other
general purpose registers besides \texttt{\%rax} can be used as well}.
We created a simple trigger program that performs a series of 28 indirect
branches
using \texttt{jmpq *\%rax} instructions, as we found that 28 jumps was the minimum
needed to reliably train the indirect branch predictor. 
Between each jump, we incremented
\texttt{\%rax} accordingly to continue on to the next jump. After these 28
jumps, we load a function pointer into \texttt{\%rax} and do a final indirect
branch using \texttt{callq *\%rax}. In our trigger, we perform these jumps
        repeatedly in a loop.

In our payload program, we first perform the same 28 indirect jumps. We ensure
the source and destination addresses of these jumps is the same as in the trigger program by
manually defining their containing function at a fixed address inside a linker
script. We also do the final indirect call to a function pointer, but with two
differences. First, the destination in the function pointer is a different
address, and second, the memory location of the function pointer itself is uncached.
This forces the CPU to predict the destination of the final indirect call while it
waits for the function pointer to load from memory. Due to the similar
history of branches with the trigger program,
the CPU will (incorrectly) predict the destination to be the same as the one in
the trigger program, which determines the speculative entry point for the
payload. Even though the in-order execution of
payload program never executes or even reads from this address, the CPU will
briefly execute instructions there speculatively.

Eventually, the dereference of the uncached function pointer in the payload program
will be resolved, and the CPU will recognize it has incorrectly predicted the
destination of its \texttt{callq} instruction. The
results from the speculative entry point instructions will be discarded, and the
CPU will continue executing from the correct destination. However, the
speculative code can change what is loaded into the cache based on its
computation, allowing it to covertly communicate its results to the ``real world'' program.



\subsection{Limits of Speculative Execution}

\FigCacheMiss

\FigSpecMeasureNP

We performed several experiments to determine how much computation can be
performed
speculatively, as well as what components are responsible for the limit.
We report results from our experiments on an Intel~Xeon-1270 (Sandy Bridge),
though we note we found similar results across other Intel processor generations,
including an i5-7200U (Kaby Lake), % jack
an i5-4300U (mobile Haswell), % ewust laptop
an i5-4590 (desktop Haswell), % ewust desktop
as well as an AMD EPYC 7251. % envy
% For simplicity, we report results from only the Xeon-1270.



\subsubsection{Cache Miss Duration}
When executing instructions speculatively we rely on a memory load of a function
pointer from uncached memory. Thus, one potential limit on our computation comes
in the form of the time it takes for the memory read to return with a result
(and for the CPU to determine the result was mis-predicted).
We measured the number of cycles a
cache miss takes to return by artificially evicting an item from cache and
timing reads from its address.
Figure~\ref{fig:cache-miss} shows the CDF of cycles taken. In the typical case,
an evicted item takes approximately 300 clock cycles to load from the Level 3 cache (L3), which
would allow a limit of roughly 200 speculative instructions to be
executed during that time. We note that when an item is not in L3, it takes
considerably longer to load, in theory allowing for thousands of speculative
instructions in a significant fraction of runs.


\subsubsection{Reorder Buffer Capacity} \label{sssec:ROB}
We also measured the capacity of the reorder buffer (ROB) using a method
outlined by~\cite{measuring-rob}. We measure the maximum number of cycles taken
to perform two uncached memory reads, and vary the number of filler instructions
between them. If the number of filler instructions is small, both memory reads
will fit inside the ROB, and it can issue their memory reads in parallel.
However, if the filler instructions fill the ROB, the second memory read will
have to wait for the first to return before it can be issued, causing a
noticeable step increase in the cycle count. Figure~\ref{fig:spec-capacity-np}
shows this step occurs at approximately 220 instructions for our processor,
suggesting a hard upper bound regardless of how long the cache miss takes to
resolve.

%TODO: explain why it's noisy? why does the maximum number of cycles drop below
%this when we're above 220 instructions? Is the step somewhere above that, but
%other processes have crept in (but occasionally, we get lucky and it's just us)?

\subsubsection{Speculative Instruction Capacity}

To verify the upper limit of speculative instructions, we instrumented our
trigger and payload programs to test a simple gadget of variable-length before it
communicated a signal to the real world via a cache side channel. If the cache
side channel revealed no signal in the real world, then we know the speculative
execution did not make it to the signal instructions before the mis-speculated
branch was resolved.

We also tested whether instruction complexity or data dependencies impact the
number of instructions that can be completed. We find that data dependencies and
instruction complexity both have an impact on the number of instructions that
can be executed. Instruction complexity is determined by the number of $\mu$~ops
that the instruction uses, which appears to be what is tracked in the ROB. For
instance, on our architecture, the 64-bit \texttt{idiv} instruction takes 59~$\mu$~ops,
and we can execute up to 3 of them in the speculative world.
Meanwhile, we can execute up to 18 32-bit \texttt{idiv} instructions, which each
take 9~$\mu$~ops~\cite{intel-instruction-tables}. These suggest we can execute
on the order of 175~$\mu$~ops before the speculative world expires.

We found that the processor can identify some operations that have no effect on
output registers and allows them to use the entire size provided by the ROB, as
determined in Section~\ref{sssec:ROB}. This includes idomatic no-ops and zero
idioms, which have no reliance on register values, for example the instruction
\texttt{xchg \%rax, \%rax} and \texttt{xor \%rax, \%rax}. However, if an
instruction is a potential data hazard, it must use an entry in the Physical 
Register File (PRF) until it reaches the correct stage in the execution pipeline. 
In this case, the number of instructions could be limited by the PRF
entries available.

%TODO: is this true? Or better explained by the micro-op story?

Most notably instructions that use the extended x86 registers are still valid
within the speculative context. Specifically, Intel's hardware accelerated
AES-NI encryption and decryption instructions, which each use 128-bit registers.
As shown in Figure~\ref{fig:spec-capacity-np}, speculative environments can
complete a significant number of AES rounds---over 100 rounds in our
experiments, more than enough to decrypt a
full block using simple AES modes (e.g. AES-CTR). We investigate the use of AES
instructions in the spculative environment further in
Sections~\ref{subsec:decryption}.

\medskip

We find that when executing speculatively, the number of instrutions completed
is rarely limited by cache miss duration. Instead
ROB size and processor mechanisms for resolving
data dependencies define an upper boundary of approximately 150
instructions\footnote{While \texttt{nop} is able to execute up to the full 220
ROB capacity, instructions that do useful work (and/or use multiple $\mu$ ops) cannot reach this limit}.

% TODO: 
% - Highlist instruction signal variablity (add v mul v aesdec v nop)?
% - Limitation is in the ROB (cite other work that supports this)
% - MORE PROCESSORS for testing?
% - ARM?


\subsubsection{Hyperthreading}
\label{sssec:hyperthread}

\FigSpecMeasureParity

When running our tests, we assign the payload and trigger program to the same
core using \texttt{taskset}. We note in the absence of \texttt{taskset}, we can
run multiple instances of trigger programs to occupy all cores, eventually
having the payload program and trigger program become co-resident.

We also explore using hyperthreading, where the CPU presents two virtual cores
for each physical core, allowing the OS to schedule programs to each
simultaneously. In effect, this can cause the interleaving of instructions
between two programs to be much finer-grained: at the instruction level rather
than changing only at the OS-controlled context switch. We find that this
has two effects on speculative programs. First, the finer-grained interleaving
allows for a higher hit rate from the cache, suggesting that each indirect jump
pattern is more likely to result in speculatively executing from the intended
position. % TODO: can we quantify this?
Second, because the physical CPU is being shared, it effectively halves the
number of instructions that can be run in the speculative context.
Figure~\ref{fig:spec-capacity-parity} shows the instructions that can be run when
running trigger and payload on a single core vs.\ a pair of hyperthreaded cores.

We note that Single Thread Indirect Branch Predictors (STIBP) have been implemented
in most environments to prevent cross thread branch predictor interference.
While this does remove the \speculake trigger's influence in scenarios where a
process runs on an isolated cpu, in most modern environments
tasks are scheduled to all available processors. This means that the trigger and
payload will be coresident eventually, allowing progress to continue.


\subsubsection{Nested Speculation}
\label{sssec:nested-spec}

We explore the ability for the CPU to ``double speculate'', where a second
stalled indirect jump while the CPU is already speculating causes it to predict
the target and
speculate a second time. For instance, suppose a payload program truly jumps to
target A, but the CPU is mistrained by a trigger program that jumps to B, thus
causing the payload program to speculatively execute at B. At B, suppose there
is a second indirect jump, perhaps using the same register as the first jump
(which has still not resolved). If the trigger program jumps to C, the payload
program may speculate a second time and continue speculative execution at~C.

We find that not all Intel CPUs support nested speculation. For
example, it appears Haswell chips do not speculate while already speculating,
but nonetheless support non-nested \speculake. Both Sandy Bridge (which
preceeded Haswell) and Kaby Lake (which followed Haswell) support nested
speculation. We find that when a CPU does support nested speculation, there
appears to be no limit to nested depth besides the speculative instruction
limit. We use a 16-deep nested speculation in Section~\ref{subsec:impl-aes}
to protect speculative decryption keys from reverse
engineering.

\subsection{Speculative Primitive}

We summarize our findings into a \emph{speculative primitive}, which allows our payload program to
speculatively (and covertly) perform on the order of 100 arbitrary
instructions while an accompanying trigger program is running, and communicate
a short (e.g. single byte) result to the real
world via a cache side channel. These speculative instructions are able to read
from any real-world memory or registers, but they cannot perform updates or
writes directly. To update memory, the speculative instructions must communicate
to the real world. We use a cache side channel to do so, but other side channels
compatible with Spectre could also be used~\cite{kiriansky2018speculative}.

We note a performance tradeoff between the size of communication (e.g. 4 bits vs 8
bits) and the time it takes the real world to recover the result from the side
channel. Using Flush+Reload~\cite{yarom2014flush+} as our cache side channel,
recovering the result requires accessing all elements in an array exponential in
the size of the result (e.g. $2^8$ array reads to recover an 8-bit result).
Therefore, there is a
performance advantage for keeping the size of the result small, and communicating
out small pieces of information that are aggregated by the real world over multiple speculative executions.
Meanwhile, smaller channels introduce more overhead in recovering information. We
investigate this tradeoff in Section~\ref{subsec:impl-aes}, and find that 8~bits
is near optimal in practice.

%%%%%%%%%%%%%%
