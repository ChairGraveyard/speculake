


\newcommand{\FigHighLevel}{
\begin{figure}[ht]
    \centering
    % \includegraphics[clip, trim=6cm 13.5cm 3.8cm 5cm, width=0.9\linewidth]{figures/exspectre-high-level.pdf}
    \includegraphics[width=0.9\linewidth]{figures/exspectre-high-level-new.pdf}
    \includegraphics[width=0.4\textwidth]{figures/ExSpectre_CR_key.png}
    \caption{\textbf{\speculake}\,---\,%
    Both the trigger and payload binaries perform the same initial series of
    indirect jumps (Step 1), with the goal of having the trigger program
        (mis)train the branch predictor. In the payload program,
    \texttt{fn\_ptr} has been set to point to the \texttt{cache\_timing}
    function but is flushed from cache. Following the pattern in the trigger 
    program, the branch predictor mis-predicts the jump (Step 2) and instead
        speculatively jumps to \texttt{target\_fn} (red line). \texttt{target\_fn}
        briefly executes speculatively (Step 3), until the \texttt{fn\_ptr} is resolved
        and the process redirects computation to the (correct) \texttt{cache\_timing} function
        (Step 4). This function then measures information computed in the speculative
        \texttt{target\_fn} by measuring a covert cache side channel.}
    \label{fig:high-level}

\end{figure}
}


\newcommand{\FigNestedSpec}{
\begin{figure}[t]
    \centering
    % \includegraphics[clip, trim=6cm 13.5cm 3.8cm 5cm, width=0.9\linewidth]{figures/exspectre-high-level.pdf}
    \includegraphics[width=0.95\linewidth]{figures/ExSpectre_CR_Nested.pdf}
    \caption{\textbf{Nested Speculation}\,---\,%
    Some CPUs support nested speculation, allowing the branch predictor to speculate
        a branch while already executing speculatively. We use this to obfuscate \textbf{key
        derivation}. The trigger program executes a sequence of indirect jumps, which
        the payload program will follow speculatively. Each jump target in the
        payload program will add a small number of bits to a speculatively-computed
        key. Without knowing the exact pattern of jump targets (specified only in the
        trigger program), the analyst will be unable to determine the key when a sufficient
        speculative depth/number of targets is used. In our implementation, we used a
        speculative depth of 16 with $2^8$ targets to derive a 128-bit key. While the \textit{decryption gadget} may
        be easy for an analyst to find, without the key, the encrypted data remains
        inaccesible.}
    \label{fig:nested-spec}    

\end{figure}
}


\newcommand{\FigSpectreOne}{
\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/spectre_1_training.png}
    \caption{\textbf{Speculative buffer overflow warm-up}\,---\,%
    The direct branch predictor must
    be trained to expect that a branch will go a specific way before speculative
    buffer overflows can be used. We varied the number of times a branch was trained
    to be taken and observed the fraction of times we achieved a speculative buffer overflow
    execution immediately after (measured by observing if a speculatively-loaded value was present
    in cache avgeraged over 20,000 trials). We find that a branch must be trained in a
    direction hundreds of times before it can be reliably used in a speculative buffer overflow.}
    \label{fig:spectre-one}
\end{figure}
}


\newcommand{\FigSpectreOneModel}{
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/spectre_1_model.png}
    \caption{\textbf{Speculative Buffer Overflow}\,---\,%
    Safe input values are stored into a local array (Step 1),
    training the branch predictor to bypass the bounds check when given
    unsafe input (Step 2). This results in a speculative array store which
    overflows the bounds and overwrite a return address (Step 3). The CPU's 
    store-to-load forwarding will forward the speculative overflow to the 
    return (Step 4), where it will steer speculative execution to the 
    attacker-specified speculative entry point (Step 5). Eventually, the 
    original bounds check is resolved and control flow is redirected to the 
    cache timing function (Step 6). }
    \label{fig:spectre-one-model}
\end{figure}
}


\newcommand{\FigSpecMeasureNP}{
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Speculative_measurements_no-parity.png}
    \caption{\textbf{Speculative limits}\,---\,% To find the number of
    We placed a memory read after an
        increasing number of (speculatively executed) instructions and measured the
        fraction of times the
        loaded value was subsequently in cache. This tells us the upper bound of
        instructions we can reliably execute speculatively. We identify two
        limitations on the speculative lifetime:
        cache miss latency resolving the speculative branch, and the
        CPU's reorder buffer~(ROB) size. We observe that different instructions have
        varying speculative limits: for example, a 32-bit \texttt{idiv} can
        complete only 18 instructions, as each instruction inserts 10 $\mu$-ops
        into the ROB, while cheaper instructions that use fewer $\mu$-ops can execute
        more instructions.}

        % I think below is too much detail for the caption; it's likely to
        % confuse more than illuminate. We can leave this info in the text, but
        % 1) I don't know that the figure definitively shows what we're saying
        % here, and 2) it buries the more important (almost obvious) takeaway:
        % some instructions can execute longer speculatively, and modern CPUs
        % are complicated!

    %    We find that the hit fraction for
    %instructions with a ratio of cycle latency to $\mu$~ops greater than 1
    %undergo a steep drop to $\approx$ 0.1 hit fraction before falling
    %definitively to 0. The drop in hit fraction indicates that the duration of
    %the test in cycles is beyond the first step in cache latency as shown in
    %Figure~\ref{fig:cache-miss} (approx. 300 cycles). Whether or not the
    %instruction sequence reaches the cycle count limit we see only a sharp drop
    %in hit fraction to 0 indicating the limiting factor is ROB size. For
    %example, we identify 18 as the maximum number of \texttt{idiv (r32)}
    %instructions computable speculatively, limited by ROB (not including
    %$\approx$ 15 instructions for signal gadget), with a soft limit at 12
    %instructions enforced by the cache latency. We measure the ROB size by
    %timing two cache accesses with a variable number of instructions between
    %them and note that this aligns with the measured maximum \texttt{nop}
    %instrustions.}
    \label{fig:spec-capacity-np}
\end{figure*}
}


\newcommand{\FigSpecMeasureParity}{
\begin{figure}[b]
     \centering
        \includegraphics[width=1.05\linewidth]{figures/Speculative_measurements_parity.png}
        \caption{\textbf{Hyperthreading}\,---\,% The trigger program influences
        We measured the impact hyperthreading has on speculative execution.
        Trigger and payload programs running on the same logical core require
        a context switch to alternate processes, but allows each to have full
        utilization of the ROB and execution units when they run.
        Running the programs on parity hyperthreads (denoted by (P))
        allows them to run simultaneously without context switching,
        but we observe this configuration effectively halves the amount that
        each program can speculatively execute, suggesting that hyperthreads share
        parts of the ROB or execution units.}
    \label{fig:spec-capacity-parity}
\end{figure}
}


\newcommand{\FigSpecMeasure}{
\begin{figure*}[t]
     \centering
        \includegraphics[width=0.9\textwidth]{figures/Speculative_measurements.png}
    \caption{The speculative primitive allows for a limited number of instructions
        to be completed speculatively, dependent on multiple factors. Trigger and 
        payload processes must share CPU resources as they must be performed on 
        the same hyperthread or associated parity hyperthreads. Processes on
        the parity hyperthreads (warm colors) denoted by (P) accomplish a 
        significantly lower number of instructions as compared with processes 
        on the same hyperthread (cool colors).}
    \label{fig:spec-capacity}
\end{figure*}
}


\newcommand{\FigCacheMiss}{
\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/cache_miss_dist}
    \caption{\textbf{Cache latency}\,---\,%
        Cumulative distribution function of the cache hit and miss latency
        for an Intel Xeon-1270 and AMD Epyc 7251. If a cache miss is used
        to force CPU speculation, the CPU must wait at least 300-800 cycles
        before the speculated branch can be resolved. However, we find the CPU
        is occasionally limited to far fewer instructions speculatively, suggesting another
        limit is at play.}
    \label{fig:cache-miss}
\end{figure}
}


\newcommand{\FigGeneralModel}{
\begin{figure}[t]
    \centering
        \includegraphics[width=0.4\textwidth]{figures/general_model.pdf}
        \caption{\textbf{ExSpectre model}\,---\,%
        General model of speculative computation within the payload 
        process when triggered. The \textit{Speculative Gadget} has read-only
        access to all memory within the process, but can only return updates/results via a
        cache side channel (by accessing the \texttt{probe\_array}).
        The process can subsequently
        \textit{Reload} from the cache side channel to learn the speculatively-computed result,
        and update the state of the \textit{Real World} process.}
    \label{fig:general_model}
\end{figure}
}


\newcommand{\FigSpecBandwidth}{
\begin{figure}[t]
    \centering  
        \includegraphics[width=0.5\textwidth]{figures/Speculative_bandwidth}
        \caption{\textbf{Speculative Bandwidth}\,---\,%
        Using our speculative primitive, 1KB of data
        can be decrypted and exfiltrated at a speed of 5.38~Kbps from
        the speculative world with 20 redundant iterations per round (to ensure
        correctness). Increased channel width exfiltrates more data per round,
        but takes longer to measure the cache side channel. Optimal throughput is
        achieved with an 8-bit channel.}
    \label{fig:spec_bandwidth}
\end{figure}
}

\newcommand{\FigSpasmModel}{
\begin{figure}[b]
    \centering
        \includegraphics[width=0.46\textwidth]{figures/spasm_model.pdf}
        \caption{\textbf{SPASM model}\,---\,%
        Our SPASM emulator speculatively decrypts instructions, and emulates
        them in the real world. The \textit{Speculative Computation} decrypts
        the encrypted SPASM binary using AES, returning the result through the side channel
        to allow the \textit{Real World} to update the emulated state
        and make system calls on behalf of the speculative world.}
    \label{fig:spasm_model}
\end{figure}
}

\newcommand{\FigTuringSuccess}{
\begin{figure}[t]
    \centering
        \includegraphics[width=0.46\textwidth]{figures/SuccessAndTime}

    \caption{The number of steps and error rate of a the 5-state Busy
            Beaver configuration were measured as a function of how many
            (redundant) iterations into the speculative world were performed. As
            expected, the amount of time to complete a million steps is a
            linear function of how many indirect calls into the speculative
            world we take. Additionally we see that it only requires using 10
            speculative calls per step to achieve a very low number of
            errors in reaching a million instructions, making 10-20 steps
            an attractive choice for most applications.}

    \label{fig:turing_success}
\end{figure}
}

\newcommand{\processorTable}{
\begin{table}
    \centering
    % \resizebox{\linewidth}{!}{\begin{tabularx}{\linewidth}{X X X| Y Y Y}
    \begin{tabularx}{\linewidth}{X b b| Y Y Y}
        \toprule
        \ \newline
        Processor &
        %Year\newline
        \ \newline
        Released &
        Micro- %\newline
        arch. & Nested\newline 
        Spec. &
        Indirect jumps & $\mu$-ops\newline
        (nop)\\
        \hline
        Intel Xeon CPU E3-1276 v3 & 2014 & Haswell &            & 26 & 178\\
        Intel Core i5-7200U       & 2016 & Skylake & \checkmark & 26 & 220\\
        Intel Xeon CPU E3-1270 v6 & 2017 & Skylake & \checkmark & 28 & 220\\
        AMD EPYC 7251             & 2017 & Ryzen   &            & 4  & 178\\
        \toprule
    \end{tabularx}%}
    \caption{\textbf{Processor features}--- We analyzed the capability of
    \speculake on three Intel processors and one AMD. Both Skylake processors
    were capable of nested speculation (Section~\ref{sssec:nested-spec}).
    Indirect jumps is the number of common training indirect jumps needed
    in the trigger program to reliably ($ > 95\%$ of the time) coerce the
    payload program to follow the pattern and jump to the speculative entry
    point specified in the trigger program. $\mu$-ops is the upper bound
    of $\mu$-ops that can be performed speculatively.}

    \label{table:processors}
\end{table}
}
