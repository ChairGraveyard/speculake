
\section{Implementation and Evaluation}
We now discuss the details of our implementations and the information learned
about speculative execution gained by these experiments. We discuss how we gain
confidence in information passed back, and how a low number of iterations is
sufficient to gain a strong confidence in results.

For each of these payloads, we used our custom trigger program that performs 28
indirect jumps, followed by a final indirect jump to a function pointer that
pointed to a gadget at address 0x430000. In each of our payload programs,
we performed the same 28 indirect jumps and the final indirect jump with the
function pointer with two differences: first, the function pointer was cleared
from the cache (using the \texttt{clflush} instruction), and second, the
function pointer pointed to a different destination (specifically, to a
function
that measured the cache side channel, recording the indexes in the probe array
that appeared to be in the cache and then flushing all indexes).
At address 0x430000, we placed the code for our speculative gadget within the 
payload program, which is never directly called
(but executes speculatively). We note that this code must be loaded into the
cache but otherwise need not be accessed directly.


\subsection{Turing Machine}
\label{subsec:impl-turing}

We implemented a 2-symbol 5-state Busy Beaver Turing machine logic in a  
payload application. The gadget implementation reads a global state,
tape, and position, and determines how the state, tape, and position should be
updated. It encodes this update into a single byte, and loads from a global
buffer indexed by that byte, loading it into cache.
We randomized the stride length between indexes in
this array to avoid the CPU's stride prediction from preemptively loading values
in the buffer.


Our implementation is able to examine the state and current symbol on the Turing
tape and make decisions (in the speculative world) based on these values as long
as they are in cache. If one of these becomes uncached, one of two things will
happen. First, the speculative gadget may simply fail to report any result back
to the real world, as the uncached read takes too long to return before the
speculative world is squashed by the resolution of the function pointer. Second,
the CPU may \emph{speculate} on the value of the uncached item, which may be
incorrect. Of course, this does not affect the correctness of normal programs,
but it does impact the correctness of our speculative code. In particular, the
speculative gadget will compute using an incorrect value of state or current
symbol, and ultimately report the wrong update.


This error is particularly devious, as it is not an
error of bit flips or noise, but rather the processor speculating what the
speculative gadget will read from memory. Thus, error correcting codes on
the reported result do not improve the situation.


We implemented the 5 state Busy Beaver configuration which requires over 47
million steps to complete. In order to have confidence the speculative gadget
executed with the correct inputs and reported the computed result correctly, we
repeat the execution a number of times and look for the value that was detected
as present in the cache most often over all the iterations. We measured the
error rate of our implementation as a function of how many redundant iterations
of the same step. Our Turing implementation discovered that 10 repetitions is
sufficient for the real world to determine the correct value, as the ``hit
rate'' for any one iteration observing the correct value loaded in cache was
over 80\%. Additionally we found that the speculative world could correctly
compute a million instructions with no errors at a rate of 324 instructions per
second.

% Target_fn returning next step given access to current state in global vars
%   - busy beaver
%   - cache page speculation on repetetive cycles. 
%       - mis-predict w/in speculative world 

% speed (complete smaller busy beaver?)
% against reference python implementation?

\subsection{AES Decryption}
\label{subsec:impl-aes}
The speculative world is able to take advantage of the AES-NI instructions to
decrypt messages. However, the speculative upper-limit of 220 instructions is not
enough to allow us to compute the key expansion, even using the
\texttt{aeskeygenassist} instructions. To avoid this, we preload the expanded
key schedule into the program, rather than the key. We note that an analyst
could observe the structure of a normal key schedule,
but we can avoid this by simply selecting 11 random round keys.
While this alternative key schedule variant is not ``true'' AES, we can easily
make the same change in our respective encryption function to make it compatible.
We note that
this should not weaken the security of AES, as we can ensure the round keys are
not linearly related.
We discuss further methods for obfuscating
the key in Section~\ref{subsec:nested-spec}.


We wrote our AES decryption payload in 35 x86\_64 instructions and 2 lines of C
(which compiles to an additional 31 x86\_64 instructions). The payload
implements AES-CTR mode decryption, reading a global index and returning the
decrypted byte at that location in the ciphertext via the cache side channel.
In this model, the speculative function decrypts a full 16-byte AES block each
iteration, but only returns the bits specified by the index.

We demonstrate the speed that information can be decrypted via the speculative
world, and we vary the channel width of the side channel from 1 to 12 bits to
measure its performance. At low channel width, reading from the cache side
channel requires timing reads from only 2 locations, while at 12-bits, the side
channel requires reading $2^{12}$ locations. On the other hand, there is a fixed
overhead per speculative iteration that favors increased channel width to maximize
bandwidth. As shown in Figure~\ref{fig:spec_bandwidth}, 8 bits is the optimal
side channel width, allowing us to decrypt over 5,000 bits per second (625
Bytes/sec).
% Iterations: 20


\subsubsection{Obfuscating keys with nested speculation}
\label{subsec:nested-spec}

An analyst could locate the speculative entry point for our
decryption gadget by
searching for AES-NI instructions in the payload program's dead code, ultimately
discovering the keys that it uses. However, we find it is possible to overcome
this by having the trigger program communicate the decryption key to the payload
program via the branch predictor.

To accomplish this, we use multiple speculative entry points, each that derives a
different decryption key before calling a common decryption routine. Since
the exact speculative entry point is determined by the trigger program, an
analyst cannot discover the decryption key directly from the payload program.

An analyst could still enumerate all potential entry points, testing each one
until they find one that correctly decrypts the ciphertext. In a 1~MB binary,
there are (at most) only 1~million entry points, providing just 20~bits of
security.

To increase security, we instead use nested speculation to \emph{chain} entry points
together. Rather than derive
the key from a single entry point, we have each potential entry point perform
another indirect jump that the CPU cannot immediately resolve, forcing it to
speculate while already executing speculatively. The predicted target of that jump
will also be determined by the trigger program. For example, if the trigger
program makes 30 training jumps, followed by 10 additional indirect jumps, and
the payload program performs the same 30 training jumps before a stall, the CPU
will predict the payload program will also perform the next 10 jumps. If each
jump has the potential to land in up to 1024 possible locations, this would
provide in total $1024^{10} = 2^{100}$ possible keys, or 100~bits of security.
%We describe our implementation of this nested speculative execution concept in
%Section~\ref{subsec:nested-spec}.

\smallskip

We implemented this technique, making 256 speculative landing spots, that each
shifted 8 unique bits into the 128-bit register \texttt{\%xmm0}, and then
performed an indirect jump. We then had the trigger program perform 16
indirect jumps that corresponded with 16 randomly-chosen landing spots in the
payload program, training the branch predictor. When the payload program reaches the
first speculative jump, it follows the same pattern speculatively, 
eventually filling
\texttt{\%xmm0} with the corresponding $16*8$ bits. We then used
the \texttt{aesenc} instruction to expand these 128-bits to a full
key schedule, and performed decryption as described previously.



%While the \speculake model acheives only moderate decryption speed, the 
%critical computation of the decryption is done in the speculative world. 
%To further mask secure this decryption we make use of nested speculation 
%to obfuscate the key schedule, discussed in section~\ref{subsec:nested-spec}.

\FigSpecBandwidth

\subsection{Virtual Machine}
\label{subsec:spasm}

% \subsubsection{SPASM}
% \label{subsubsec:spasm}

%Constructing an emulator making use of the speculative primitive requires  
%a trade off in expresive capability versus speed. 
We have implemented our custom instruction set architecture---SPASM---as a model
using two pseudo-registers, and
6-bit instruction length which allows for a relatively direct programming model
in which structured values can be entered into memory locations before making
a systemcall.


%To achieve a balance with speed the number of bits in each instruction is both 
%fixed and minimized.  A variable length instruction would require that the 
%\texttt{Flush+Reload} stage search the maximum number of bits on each round, and each 
%aditional bit doubles the search space that the \texttt{Flush+Reload} stage must 
%traverse.  So every bit shorter effectively doubles the throughput of the emulator~\footnote{Until it doesn't}, 
%and there is effectively no advantage to allowing variable length 
%instructions. 
%

In this model of computation there are effectively no instruction arguments, as we must
return an entire instruction from the speculative world inside the limited-width
cache side channel. Although other small
instruction sets exist, they either allow variable instruction
lengths, are too long even in reduced form, or did not have significant support
to make them favorable for developers.

We used 6 bits in the construction of this instruction set as our
goal is to limit the length of each opcode as much as possible. Note that this
is different from the goal in maximizing bandwidth, as our goal now is to
maximize instruction throughput. Given our short instructions, loading values into registers
requires shifting in 4-bits at a time. SPASM has two registers that act as a
pointer and working register, that can be used to perform jumps, arbitrary
memory reads and writes, and basic arithmatic. We also have a \texttt{syscall}
instruction that makes a real system call to the underlying operating system
with parameters loaded from the SPASM state, allowing us to interact with the
real world. Details of
the SPASM instruction set can be found in Appendix~\ref{appendix:spasm}. 

In SPASM we have implemented multiple example programs that we encrypted and
loaded into a \speculake payload, which decrypts and emulates SPASM instructions
only when the corresponding trigger program is running.
We first implemented a \textit{HelloWorld}
program that prints to \texttt{stdout}. Next, a \texttt{FizzBuzz} program that
demonstrates control flow and arithmetic operations while printing to stdout.
Finally, we implemented a \textit{ReverseShell} program that opens and connects to a socket
before duplicating I/O file descriptors and executing a local shell.
Figure~\ref{fig:spasm_model} details the high-level flow of a SPASM payload.

%Expected performance for a given SPASM binary will vary given multiple factors,
%the most important of which is the \texttt{Flush+Reload} overhead. This can be
%tuned based on the specific trigger, as it is used to establish confidence that
%a signal has been identified in the indices returned from the "speculative
%world". 
%Thus accomplishing a task using SPASM generally equates to:

% \begin{lstlisting}
%     Redundancy * Probe_Space * Num_Instr
% \end{lstlisting}

Our \textit{ReverseShell} program consists of 355 SPASM instructions, and
makes six system calls to open a socket,
connect to it, duplicate I/O file descriptors, and perform an \texttt{execve}
system call to open a shell.
In our tests using 5 iterations per decrypted instruction, the
\textit{ReverseShell} program takes just over 2ms to launch a reverse shell
once triggered.

% TODO - REFERENCE APPENDIX for ISA

\FigSpasmModel

\subsection{OpenSSL Trigger}
\label{subsec:openssl-impl}

%Benign programs can also act as a trigger program, provided they perform sufficient
%indirect jumps to train the branch predictor. We experiment using the OpenSSL
%library as a potential benign trigger, as its source code has gratuitous use of
%function pointers which compile to indirect jumps. In addition, it has many
%complicated code paths that can be easily selected by remote clients by their
%choice of cipher suit

To demonstrate a benign trigger application, we implemented an ExSpectre payload that
would trigger when running concurrently with OpenSSL.
% Could cut?
For these experiments, we disable
ASLR for simplification, but note that
branch predictors can also be used to determine ASLR offsets of co-resident applications,
and our attack adjusted accordingly~\cite{evtyushkin2016jump}.

We used \texttt{gdb} to run an instance of an OpenSSL server (version 1.0.1f),
and printed out every instruction executed and its address after a breakpoint on
the \texttt{SSL\_new} function. We then made a TLS connection to the
server,
which produced over 13~million instructions, including over 359,000 direct jumps
and 28,000 indirect jumps. We then searched for the longest repeated set of more than
28 indirect jumps that end with a unique jump (i.e. source and destination do
not occur in the previous 28+ indirect jumps).

We discovered a candidate that corresponds to code in OpenSSL's
\texttt{nistp256.c} that contained 31 indirect jumps repeated 254 times in our
handshake. This code is used during the TLS key exchange as the server computes
the ECDHE shared secret. We made a list of 31 source-destination address pairs
for these indirect jumps, and constructed a jump/ret chain to mimic the same
jump pattern in
our payload program. Our payload program mimicks the first 30 indirect jump
source/destination pairs, with a final jump going to a cache timing function
in our payload program. However, due to the prior pattern, this last jump is
frequently mis-speculated (about 3.5\% of the time), and instead goes to the
destination corresponding to the 31st jump in OpenSSL, which serves as our
speculative entry point.

%Our program jumps to the source address of a pair,
%which has a single \texttt{retq} instruction that pops the next
%destination off the stack, performing the indirect jump. At each destination
%address, we place another static (direct) \texttt{jmpq} to bring execution to the
%next source address in our list. The last jump source/destination pair is not
%performed (and its destination is not pushed to the stack). However, we place
%our gadget code at the destination address, which, when executed speculatively,
%loads a specific value into the cache.
%The ``true'' destination of the last indirect jump returns to our
%payload program, which immediately times probing the cache to see if any value was
%loaded.

We ran experiments on an Intel Haswell
i5-4590 CPU, with OpenSSL and our payload program pinned to the same core using
\texttt{taskset}.
We induced the jump pattern in OpenSSL by running Apache benchmark against it to
generate thousands of TLS connections using the ECDHE key exchange with the
secp256r1 curve (ECDHE-RSA-AES256-GCM-SHA384). When running Apache benchmark locally, our payload program
reliably executes (speculatively) at the intended speculative entry point
about 3.5\% of the time. When apache benchmark runs on a remote
machine, this rate drops to approximately 2.0\%. Nonetheless, these are both
sufficient to perform computation, as our payload can simply increase the amount
of iterations needed to extract meaningful results from the speculative world.

We verified that our payload program did not execute at the speculative entry
point when we ran
other programs that simply consumed CPU on the same core. In addition, when we used
Apache benchmark to create thousands of connections with a different cipher
suite (DHE-RSA-AES128-GCM-SHA256), we similarly received no speculation. This
could allow an adversary to use an obscure or uncommon (but still
supported) cipher suite to trigger a malicious \speculake payload program on a remote server.

%%%%%%%%%%%%%%
