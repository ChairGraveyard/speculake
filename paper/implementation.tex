
\section{Implementation and Evaluation}
%We now discuss the details of our implementations and the information learned
%about speculative execution gained by these experiments. We discuss how we gain
%confidence in information passed back, and how a low number of iterations is
%sufficient to gain a strong confidence in results.

In this section, we discuss implementation details for our payload and trigger
programs.

%In each of our payload programs,
%we performed the same 28 indirect jumps and the final indirect jump with the
%function pointer with two differences: first, the function pointer was cleared
%from the cache (using the \texttt{clflush} instruction), and second, the
%function pointer pointed to a different destination (specifically, to a
%function
%that measured the cache side channel, recording the indexes in the probe array
%that appeared to be in the cache and then flushing all indexes).
%At address 0x430000, we placed the code for our speculative gadget within the 
%payload program, which is never directly called
%(but executes speculatively). We note that this code must be loaded into the
%cache but otherwise need not be accessed directly.
%


% Could move to an errata appendix?
%We randomized the stride length between indexes in
%this array to avoid the CPU's stride prediction from preemptively loading values
%in the buffer.

\subsection{Turing Machine}
\label{subsec:impl-turing}

We designed our Turing machine implementation to work with our custom trigger
program, with 28 indirect jumps mimicked by the Turing payload program.
We implemented a 2-symbol 5-state Busy Beaver Turing machine logic at the
speculative entry point (in 42 x86-64 instructions), returning the state update,
symbol to write, and tape move direction in a single byte via a cache side
channel.

We observed in our implementation that it is important that all values used in
the speculative world---as well as the code itself---be cached. If these are
evicted, the speculative code may fail to run, or the CPU may \emph{speculate}
on the value of the uncached item, which may be incorrect. While this does not
impact the correctness of normal programs whose incorrect speculations will be
resolved, our speculative code reports results back to the real world before
this resolution. In our Turing example, we observed this as incorrect state
transitions.

This error is particularly devious, as it is not an error of bit flips or noise,
but rather the processor speculating what the speculative gadget will read from
memory. Thus, error correcting codes on the reported result do not improve the
situation.


Instead, we repeat the execution several times and look for the modal value over
all iterations. We measured the error rate of our implementation as a function
of how many redundant iterations of the same step, and found that 10 redundant
iterations resulted in 1 error every million Turing steps, with the error rate
dropping exponentially as iterations increase. We choose 11 iterations as a
conservative bound (error rate measured to be 0), and computed 1 million Turing
steps at a rate of 1351 steps per second.

% Was 324 steps per second, but was that at 10 iterations? But we just said
% 10 wasn't perfect (1 error in a million steps), so it seems confusing to say
% we computed a million steps without error at 10 iterations.



% Target_fn returning next step given access to current state in global vars
%   - busy beaver
%   - cache page speculation on repetetive cycles. 
%       - mis-predict w/in speculative world 

% speed (complete smaller busy beaver?)
% against reference python implementation?

\subsection{AES Decryption}
\label{subsec:impl-aes}
The speculative world is able to take advantage of the AES-NI instructions to
decrypt messages. However, the speculative upper-limit of about 175 $\mu$~ops is
not enough to allow us to compute the key expansion, even using the
\texttt{aeskeygenassist} instructions. To avoid this, we can either preload the
expanded key schedule into the program (instead of the key), or use a cheaper
(non-standard) key expansion algorithm. For the former, we note that an analyst
could observe the structure of a normal key schedule, but we can avoid this by
simply selecting 11 random round keys. We note that this should not weaken the
security of AES, as we can ensure the round keys are not linearly related.


%We discuss further methods for obfuscating
%the key in Section~\ref{subsec:nested-spec}.
%

We wrote our AES decryption payload in 35 x86\_64 instructions and 2 lines of C
(which compiles to an additional 31 x86\_64 instructions). The payload
implements AES-CTR mode decryption, reading a global index and returning the
decrypted byte at that location in the ciphertext via the cache side channel.
In this model, the speculative function decrypts a full 16-byte AES block each
iteration, but only returns the bits specified by the index.


% TODO: this could move elsewhere?
We demonstrate the speed that information can be decrypted via the speculative
world, and we vary the channel width of the side channel from 1 to 12 bits to
measure its performance. At low channel width, reading from the cache side
channel requires timing reads from only 2 locations, while at 12-bits, the side
channel requires reading $2^{12}$ locations. On the other hand, there is a fixed
overhead per speculative iteration that favors increased channel width to
maximize bandwidth. As shown in Figure~\ref{fig:spec_bandwidth}, 8 bits is the
optimal side channel width, allowing us to decrypt over 5,000 bits per second
(625 Bytes/sec).
% Iterations: 20


\smallskip

We also implemented our nested speculation technique for obfuscating keys,
making 256 speculative landing spots that each shift 8 unique bits into the
128-bit register \texttt{\%xmm0}, and then performing an indirect jump. We then
had a custom trigger program perform 16 indirect jumps (after the initial 28)
that corresponded with 16 randomly-chosen landing spots in the payload program,
training the branch predictor. When the payload program reaches the first
speculative jump, it follows the same pattern speculatively, eventually filling
\texttt{\%xmm0} with the corresponding $16*8$ bits. We then used the
\texttt{aesenc} instruction to expand these 128-bits to a full key schedule, and
performed decryption as described previously. Thus, without the trigger program,
an analyst has no information about what key is used to decrypt the ciphertext
in the payload.



%While the \speculake model acheives only moderate decryption speed, the 
%critical computation of the decryption is done in the speculative world. 
%To further mask secure this decryption we make use of nested speculation 
%to obfuscate the key schedule, discussed in section~\ref{subsec:nested-spec}.

\FigSpecBandwidth

\subsection{Emulator}
\label{subsec:spasm}

% \subsubsection{SPASM}
% \label{subsubsec:spasm}

%Constructing an emulator making use of the speculative primitive requires  
%a trade off in expresive capability versus speed. 
We have implemented our custom instruction set architecture---SPASM---as a model
using two pseudo-registers, and 6-bit instruction length which allows for a
relatively direct programming model in which structured values can be entered
into memory locations before making a systemcall.


%To achieve a balance with speed the number of bits in each instruction is both 
%fixed and minimized.  A variable length instruction would require that the 
%\texttt{Flush+Reload} stage search the maximum number of bits on each round, and each 
%aditional bit doubles the search space that the \texttt{Flush+Reload} stage must 
%traverse.  So every bit shorter effectively doubles the throughput of the emulator~\footnote{Until it doesn't}, 
%and there is effectively no advantage to allowing variable length 
%instructions. 
%

In this model of computation there are effectively no instruction arguments, as
we must return an entire instruction from the speculative world inside the
limited-width cache side channel. Although other small instruction sets exist,
they either allow variable instruction lengths, are too long even in reduced
form, or did not have significant support to make them favorable for developers.

We used 6 bits in the construction of this instruction set as our goal is to
limit the length of each opcode as much as possible. Note that this is different
from the goal in maximizing bandwidth, as our goal now is to maximize
instruction throughput. Given our short instructions, loading values into
registers requires shifting in 4-bits at a time. SPASM has two registers that
act as a pointer and working register, that can be used to perform jumps,
arbitrary memory reads and writes, and basic arithmetic. We also have a
\texttt{syscall} instruction that makes a real system call to the underlying
operating system with parameters loaded from the SPASM state, allowing us to
interact with the real world. Details of the SPASM instruction set can be found
in Appendix~\ref{appendix:spasm}. 

In SPASM we have implemented multiple example programs that we encrypted and
loaded into a \speculake payload, which decrypts and emulates SPASM instructions
only when the corresponding trigger program is running. We have implemented a
\textit{HelloWorld} program that prints to \texttt{stdout}, and a
\textit{FizzBuzz} program that demonstrates control flow and arithmetic
operations while printing to stdout. Finally, we implemented a
\textit{ReverseShell} program that opens and connects a TCP socket to an
attacker-chosen location before executing a local shell and allowing the remote
adversary to issue shell commands on the victim machine.
Figure~\ref{fig:spasm_model} details the high-level flow of a SPASM payload.

%Expected performance for a given SPASM binary will vary given multiple factors,
%the most important of which is the \texttt{Flush+Reload} overhead. This can be
%tuned based on the specific trigger, as it is used to establish confidence that
%a signal has been identified in the indices returned from the "speculative
%world". 
%Thus accomplishing a task using SPASM generally equates to:

% \begin{lstlisting}
%     Redundancy * Probe_Space * Num_Instr
% \end{lstlisting}

Our \textit{ReverseShell} program consists of 355 SPASM instructions, and makes
six system calls to open a socket, connect to it, duplicate I/O file
descriptors, and perform an \texttt{execve} system call to open a shell. In our
tests using 5 iterations per decrypted instruction, the \textit{ReverseShell}
program takes just over 2ms to launch a reverse shell once triggered.

% TODO - REFERENCE APPENDIX for ISA

\FigSpasmModel

\subsection{OpenSSL Trigger}
\label{subsec:openssl-impl}

%Benign programs can also act as a trigger program, provided they perform sufficient
%indirect jumps to train the branch predictor. We experiment using the OpenSSL
%library as a potential benign trigger, as its source code has gratuitous use of
%function pointers which compile to indirect jumps. In addition, it has many
%complicated code paths that can be easily selected by remote clients by their
%choice of cipher suit

To demonstrate a benign trigger application, we implemented an ExSpectre payload
that would trigger when running concurrently with OpenSSL.
% Could cut?
We disable ASLR for simplification, but note that branch predictors can also be
used to determine ASLR offsets of co-resident applications, and our attack
adjusted accordingly~\cite{evtyushkin2016jump}.

We used \texttt{gdb} to run an instance of an OpenSSL server (version 1.0.1f),
and printed out every instruction executed and its address after a breakpoint on
the \texttt{SSL\_new} function. We then made a TLS connection to the server,
which produced over 13~million instructions, including over 359,000 direct jumps
and 28,000 indirect jumps. We then searched for the longest repeated set of more
than 28 indirect jumps that ends with a unique jump (i.e. source and destination
do not occur in the previous 28+ indirect jumps).

We discovered a candidate that corresponds to code in OpenSSL's
\texttt{nistp256.c} that contained 31 indirect jumps repeated 254 times each
handshake. This code is used during the TLS key exchange as the server computes
the ECDHE shared secret. We made a list of 31 source-destination address pairs
for these indirect jumps, and constructed a \texttt{jump}/\texttt{ret} chain to
mimic the same jump pattern in our payload program. Our payload program mimics
the first 30 indirect jump source/destination pairs, with a final jump going to
a cache timing function in our payload program. However, due to the prior
pattern, this last jump is frequently mis-speculated (about 3.5\% of the time),
and instead goes to the destination corresponding to the 31st jump in OpenSSL,
which serves as our speculative entry point.

%Our program jumps to the source address of a pair,
%which has a single \texttt{retq} instruction that pops the next
%destination off the stack, performing the indirect jump. At each destination
%address, we place another static (direct) \texttt{jmpq} to bring execution to the
%next source address in our list. The last jump source/destination pair is not
%performed (and its destination is not pushed to the stack). However, we place
%our gadget code at the destination address, which, when executed speculatively,
%loads a specific value into the cache.
%The ``true'' destination of the last indirect jump returns to our
%payload program, which immediately times probing the cache to see if any value was
%loaded.

We ran experiments on an Intel Haswell i5-4590 CPU, with OpenSSL and our payload
program pinned to the same core using \texttt{taskset}. We induced the jump
pattern in OpenSSL by running Apache benchmark against it to generate thousands
of TLS connections using the ECDHE key exchange with the secp256r1 curve
(ECDHE-RSA-AES256-GCM-SHA384). When running Apache benchmark locally, our
payload program reliably executes (speculatively) at the intended speculative
entry point about 3.5\% of the time. When apache benchmark runs on a remote
machine, this rate drops to approximately 2.0\%. Nonetheless, these are both
sufficient to perform computation, as our payload can simply increase the amount
of iterations needed to extract meaningful results from the speculative world.

We verified that our payload program did not execute at the speculative entry
point when we ran other programs that simply consumed CPU on the same core. In
addition, when we used Apache benchmark to create thousands of connections with
a different cipher suite (DHE-RSA-AES128-GCM-SHA256), we similarly saw no
speculation at the entry point. This could allow an adversary to use an obscure
or uncommon cipher suite to trigger a malicious \speculake payload program on a
remote server.


%\FigSpectreOne

\if0
\subsection{Speculative Buffer Overflow Trigger}
\label{subsec:sbo-impl}


To demonstrate the adaptability of this attack we have implemented the 
Speculative Buffer Overflow alternative trigger and assembled an \speculake 
payload. 

We make use of text input as the trigger to the payload program in this case,
where an input file contains entries specifying length, padding length,
and data value. When a line is read the payload program makes a bounds
check on the length of padding then stores the data at that offset in a
local array. 

The local array store is now the vulnerability it can be exploited even 
with complete bounds checks. After a series of honest inputs we include 
an entry with a padding length beyond the maximum. On the runs with this
cafted input we flush from cache the maximum padding length constant in 
the payload program, preventing the bounds check from being resolved 
and allowing the data value to be speculatively stored. We 
then speculatively overwrite the return address and use store-to-load forwarding
to cause a following return to divert to the address specified by the data entry. 
From here we make use of the decryption gadget to dcecrypt SPASM instructions
from an encrypted data blob to be transmitted to the real world via cache 
side-channel. Using this method we have been able to run all SPASM payloads 
including the reverse-shell. 

We note significant unpredictability in the branch predictor, though we
show in Figure~\ref{fig:spectre-one} that a minimum around 200 safe input entries
to each dishonest entry are required before a distinguishable signal is present 
in the cache channel. 
\fi
%%%%%%%%%%%%%%
