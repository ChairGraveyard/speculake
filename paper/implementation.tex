
\section{Implementation and Evaluation}
We now discuss the details of our implementations and the information learned
about speculative execution gained by these experiments. We discuss how we gain
confidence in information passed back, and how a low number of iterations is
sufficient to gain a strong confidence in results.

For each of these payloads, we used our custom trigger program that performs 28
indirect jumps, followed by a final indirect jump to a function pointer that
pointed to a gadget at address 0x430000. In each of our payload programs,
we performed the same 28 indirect jumps and the final indirect jump with the
function pointer with two differences: first, the function pointer was cleared
from the cache (using the \texttt{clflush} instruction), and second, the
function pointer pointed to a different destination (specifically, to a
function
that measured the cache side channel, recording the indexes in the probe array
that appeared to be in the cache and then flushing all indexes).
At address 0x430000, we placed the code for our speculative gadget within the 
payload program, which is never directly called
(but executes speculatively). We note that this code must be loaded into the
cache but otherwise need not be accessed directly.


\subsection{Turing Machine}
\label{subsec:impl-turing}

\FigTuringSuccess

We implemented a 2-symbol 5-state Busy Beaver Turing machine logic in a  
payload application. The gadget implementation reads a global state,
tape, and position, and determines how the state, tape, and position should be
updated. It encodes this update into a single byte, and loads from a global
buffer indexed by that byte, loading it into cache.
We randomized the stride length between indexes in
this array to avoid the CPU's stride prediction from preemptively loading values
in the buffer.


Our implementation is able to examine the state and current symbol
on the Turing tape and make decisions based on these values as long as they are
in cache. If one of these becomes uncached, one of two things will happen.
First, the speculative gadget may simply fail to report any result back to the
real world, as the uncached read takes too long to return before the speculative
world is squashed by the resolution of the function pointer. Second, the CPU may
\emph{speculate} on the value of the uncached item, which may be incorrect. Of
course, this does not affect the correctness of normal programs, but it does
impact the correctness of our speculative code. In particular, the speculative
gadget will compute using an incorrect value of state or current
symbol, and ultimately report the wrong update.


This error is particularly devious, as it is not an
error of bit flips or noise, but rather the processor speculating what the
speculative gadget will read from memory. Thus, error correcting codes on
the reported result do not improve the situation.



In order to have confidence the speculative gadget executed with the
correct inputs and reported the computed result correctly, 
we repeat the execution a number of times and look for the value that was
detected as present in the cache most often over all the iterations.

Our Turing implementation discovered that 10 repetitions is sufficient for the
real world to determine the correct value, as the ``hit rate'' for any one
iteration observing the correct value loaded in cache was over 80\%.

We implemented the 5 state Busy Beaver configuration which requires over 47
million steps to complete. Figure~\ref{fig:turing_success} shows the
capabilities of our Turing implementation. We were able to verify that the
speculative world could correctly compute a million instructions with no errors
at a rate of 324 instructions per second.

% Target_fn returning next step given access to current state in global vars
%   - busy beaver
%   - cache page speculation on repetetive cycles. 
%       - mis-predict w/in speculative world 

% speed (complete smaller busy beaver?)
% against reference python implementation?

\subsection{AES Decryption}
\label{subsec:impl-aes}
The speculative world is able to take advantage of the AES-NI instructions to
decrypt messages. However, the speculative upper-limit of 220 instructions is not
enough to allow us to compute the key expansion, even using the
\texttt{aeskeygenassist} instructions. To avoid this, we preload the expanded
key schedule into the program, rather than the key. We note that an analyst
could observe the structure of a normal key schedule,
but we can avoid this by simply selecting 11 random round keys (and encrypting
using the same 11 round keys). We discuss further methods for obfuscating
the key in Section~\ref{subsec:nested-spec}.


We wrote our AES decryption payload in 35 x86\_64 instructions and 2 lines of C
(which compiles to an additional 31 x86\_64 instructions). The payload
implements AES-CTR mode decryption, reading a global index and returning the
decrypted byte at that location in the ciphertext via the cache side channel.
In this model, the speculative function decrypts a full 16-byte AES block each
iteration, but only returns the bits specified by the index.

We demonstrate the speed that information can be decrypted via the speculative
world, and we vary the channel width of the side channel from 1 to 12 bits to
measure its performance. At low channel width, reading from the cache side
channel requires timing reads from only 2 locations, while at 12-bits, the side
channel requires reading $2^{12}$ locations. On the other hand, there is a fixed
overhead per iteration that favors increased channel width to maximize
bandwidth. As shown in Figure~\ref{fig:spec_bandwidth}, 8 bits is the optimal
side channel width, allowing us to decrypt over 5,000 bits per second (625
Bytes/sec).


%While the \speculake model acheives only moderate decryption speed, the 
%critical computation of the decryption is done in the speculative world. 
%To further mask secure this decryption we make use of nested speculation 
%to obfuscate the key schedule, discussed in section~\ref{subsec:nested-spec}.

\FigSpecBandwidth

\subsection{Virtual Machine}
\label{subsec:spasm}

% \subsubsection{SPASM}
% \label{subsubsec:spasm}

%Constructing an emulator making use of the speculative primitive requires  
%a trade off in expresive capability versus speed. 
We have implemented our custom instruction set architecture---SPASM---as a model
using two pseudo-registers, and
6-bit instruction length which allows for a relatively direct programming model
in which structured values can be entered into memory locations before making
a systemcall.


%To achieve a balance with speed the number of bits in each instruction is both 
%fixed and minimized.  A variable length instruction would require that the 
%\texttt{Flush+Reload} stage search the maximum number of bits on each round, and each 
%aditional bit doubles the search space that the \texttt{Flush+Reload} stage must 
%traverse.  So every bit shorter effectively doubles the throughput of the emulator~\footnote{Until it doesn't}, 
%and there is effectively no advantage to allowing variable length 
%instructions. 
%

In this model of computation there are no instruction arguments, as we must
return an entire instruction from the speculative world inside the limited-width
cache side channel. Although other small
instruction sets exist, they either allow variable instruction
lengths, are too long even in reduced form, or did not have significant support
to make them favorable for developers.

We have used 6 bits in the construction of this instruction set as our
goal is to limit the length of each opcode as much as possible. Note that this
is different from the goal in maximizing bandwidth, as our goal now is to
maximize instruction throughput.

In SPASM we have implemented multiple example programs that can be run as
encrypted binaries in an \speculake payload: First, a \textit{HelloWorld}
program that prints to \texttt{stdout}. Next, a \texttt{FizzBuzz} program that
demonstrates control flow and arithmetic operations while printing to stdout.
And finally, a \textit{ReverseShell} program that opens and connects to a socket
before  duplicating I/O file descriptors and executing a local shell. Details of
the SPASM instruction set can be found in Appendix~\ref{appendix:spasm}. Figure~\ref{fig:spasm_model} details the high-level flow of a SPASM payload.

Expected performance for a given SPASM binary will vary given multiple factors,
the most important of which is the \texttt{Flush+Reload} redundancy. This can be
tuned based on the specific trigger, as it is used to establish confidence that
a signal has been identified in the indices returned from the "speculative
world". 
%Thus accomplishing a task using SPASM generally equates to:

% \begin{lstlisting}
%     Redundancy * Probe_Space * Num_Instr
% \end{lstlisting}

For example, the \textit{ReverseShell} program is 355 SPASM instructions, and
makes six system calls to open a socket,
connect to it, duplicate I/O file descriptors, and perform an \texttt{execve}
system call to open a shell.
In our tests using 5 iterations per decrypted instruction, the
\textit{ReverseShell} program takes just over 2ms to launch a reverse shell
once triggered.

% TODO - REFERENCE APPENDIX for ISA

\FigSpasmModel

\subsection{OpenSSL Trigger}
\label{subsec:openssl}

Benign programs can act as a trigger program, provided they perform sufficient
indirect jumps to train the branch predictor. We experiment using the OpenSSL
library as a potential benign trigger, as its source code has gratuitous use of
function pointers which compile to indirect jumps. In addition, it has many
complicated code paths that can be easily selected by remote clients by their
choice of cipher suite.

For these experiments, we disable ASLR for simplification, but note that
branch predictors can also be used to determine ASLR offsets and our attack adjusted
accordingly~\cite{evtyushkin2016jump}.

We used \texttt{gdb} to run an instance of an OpenSSL server (version 1.0.1f),
and printed out every instruction executed and its address after a breakpoint on
the \texttt{SSL\_new} function. We then made a TLS connection to the
server\footnote{Which took well over 2~hours, potentially making it the slowest
TLS handshake to have ever completed},
which produced over 13~million instructions, including over 359,000 direct jumps
and 28,000 indirect jumps. We then searched for the longest repeated set of over
28-32 indirect jumps that end with a unique jump (i.e. source and destination do
not occur in the previous 28-32 indirect jumps).

We discovered a candidate that corresponds to code in OpenSSL's
\texttt{nistp256.c} that contained 31 indirect jumps repeated 254 times in our
handshake. This code is used during the TLS key exchange as the server computes
the ECDHE shared secret. We made a list of 31 source-destination address pairs
for these indirect jumps, and constructed a jump/ret chain at those addresses in
our payload program. Our program jumps to the source address of a pair,
which has a single \texttt{retq} instruction, which pops the next
destination off the stack and performs the indirect jump. At each destination
address, we place a static (direct) \texttt{jmpq} to bring execution to the
next source address in our list. The final jump source/destination pair is not
performed (and its destination is not pushed to the stack). However, we place
our gadget code at the destination address, which finishes by loading a specific value
into the cache.
The last source in the 31 indirect jumps performs an indirect jump that returns to our
payload program, which immediately times probing the cache to see if any value was
loaded.

We ran these experiments on an Intel Haswell
i5-4590 CPU, with OpenSSL and our payload program pinned to the same core using
\texttt{taskset}.
We induced the jump pattern in OpenSSL by running Apache benchmark against it to
generate thousands of connections, using the ECDHE key exchange with the
secp256r1 curve (ECDHE-RSA-AES256-GCM-SHA384). When running Apache benchmark locally, our payload program
reliably achieves a 3.5\% hit rate. When apache benchmark runs on a remote
machine, the hit rate drops to approximately 2.0\%. Nonetheless, this is
sufficient to perform computation, as we simply perform thousands of iterations
to extract results from the speculative world before updating any real world state.

We verified that our payload program did not observe any cache loads when we ran
other programs that consumed CPU on the same core. In addition, when we used
Apache benchmark to create thousands of connections with a different cipher
suite (DHE-RSA-AES128-GCM-SHA256), we similarly received no hit rate. This
could potentially allow an adversary to use an obscure or uncommon (but still
supported) cipher suite to trigger a malicious payload program on a remote server.

\subsection{Nested Speculation}
\label{subsec:nested-spec}

We note that an analyst might attempt to locate the speculative entry point by
searching for AES-NI instructions in the payload program's dead code, ultimately
discovering the keys that it uses. However, we find it is possible to overcome
this by having the trigger program communicate the decryption key to the payload
program via the branch predictor.

To accomplish this, we use multiple speculative entry points, each that derive a
different decryption key before calling a common decryption routine. Since
the exact speculative entry point is determined by the trigger program, an
analyst cannot discover the decryption key directly from the payload program.

An analyst could still enumerate all potential entry points, testing each one
until they find one that correctly decrypts the ciphertext. In a 1~MB binary,
there are (at most) only 1~million entry points, providing just 20~bits of
security.

To increase security, we \emph{chain} entry points together. Rather than derive
the key from a single entry point, we have each potential entry point perform
another indirect jump that the CPU cannot immediately resolve, forcing it to
speculate while already executing speculatively. The predicted target of that jump
will also be determined by the trigger program. For example, if the trigger
program makes 30 training jumps, followed by 10 additional indirect jumps, and
the payload program performs the same 30 training jumps before a stall, the CPU
will predict the payload program will also perform the next 10 jumps. If each
jump has the potential to land in up to 1024 possible locations, this would
provide in total $1024^{10} = 2^{100}$ possible keys, or 100~bits of security.
%We describe our implementation of this nested speculative execution concept in
%Section~\ref{subsec:nested-spec}.


%%%%%%%%%%%%%%
