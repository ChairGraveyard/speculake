
\section{Application Payloads}

While the amount of computation done in a single speculative execution is small,
we demonstrate several applications that can take advantage of multiple
speculative runs to carry out computation.

As a first step, we observe that the speculative primitive can be used to
trivially implement a finite state machine: logic can be done in the speculative
world, while updates to the state are communicated to the real world where they
are stored. On the next run of the speculative instructions, the state is read
from the real world state (along with any inputs), state transitions are
computed and communicated back. In this mode, the state is maintained by the
real world, while updates are controlled by code executed speculatively.

We further observe we are not limited to finite state machines, but can support
any model of computation where \emph{updates} to any state are finite (i.e. can
fit within the bandwidth constraints of the speculative primitive). This
encompases Turing machines~\cite{turing1937computable} as well as certain random
access machines, which we investigate next. Figure~\ref{fig:general_model}
demonstrates the execution flow of a sample \speculake malware.

%Next, we observe that the instructions to be executed speculatively can be
%obscured further by encrypting them. This encryption allows for hidden
%computation, instructions are stored in the real world encrypted, they are then
%decrypted in the speculative world and passed to the real world to be executed.
%This method makes it appear as though the program is generating its own code.

\FigGeneralModel

\subsection{Turing Machine}
\label{subsec:turing}
To demonstrate that arbitrary computation can be performed cooperatively between
the speculative world and real world, we implement a Turing machine, and
configure it to run a 5-state Busy Beaver
function~\cite{turing1937computable,chaitin1987computing,herken1992universal}.
This configuration allows us to run a large number of steps with very minimal
logic.
%The Busy Beaver is a configuration which writes the most
%1s on the tape before halting with a limited number of states.

Updates to this Turing machine are computed speculatively, while the real
world keeps track of the state and full tape of the machine. Thus, the logic of
the machine is entirely contained in the speculative world, while the state may
be externally visible (e.g. to a dynamic debugger). We note that the machine
only operates when the trigger executes, making it difficult for an analyst with
only access to the Turing machine to determine exactly what the machine will do
from its initial state.

However, this toy example is meant only as an illustrative example of arbitrary
computation, not as a robust means of obfuscation. Indeed, even the initial
state of a Turing machine alone may reveal a significant amount of information.
Furthermore, the analyst may attempt to locate potential speculative entry
points, even without the help of the trigger program. We describe ways to
address both of these next.


\subsection{Unpacking and Decryption}
\label{subsec:decryption}

While a Turing machine demonstrates that arbitrary speculative computation
is possible, hiding malware this way has several drawbacks. First, Turing
machines are a poor choice for practical computation, as they are inefficient
and have no direct way to interface with the rest of the system (e.g. via system
calls). Second, as mentioned, they leave a great deal of information available
to the analyst, including the initial tape state, and a potentially small
(enumerable) number of possible speculative entry points.

We explore a more practical application of using \speculake to perform
\emph{decryption} speculatively. To hide keys from the analyst, the key and decryption
code only occur in the speculative world, while the initial payload program
contains only the ciphertext. While partial plaintext will be available in the
real world during execution, we emphasize that this only occurs when the trigger
runs. Before this, the state of the program reveals only the ciphertext that
will be decrypted. While the speculative entry point enumeration attack could be
used to reveal the keys used to decrypt this ciphertext, we describe a way to
derive the decryption key entirely from the trigger program. Thus, an analyst
that only has access to the payload program will be unable to learn the key or
decrypt the embedded ciphertext.

We also note that even when the trigger runs, decryption does not occur outside
the speculative context, meaning that any traditional traps or debugging
breakpoints placed on decryption instructions or routines will not occur, even
as they are used speculatively. These instructions could even be obfuscated themselves by
placing them in other misaligned instructions, and choosing a speculative entry
point that jumps to the middle of other instructions.


We note that 200 instructions is too short for most software-implemented
cryptography. However, modern Intel CPUs provide hardware support for AES, which
we find only takes a handful of $\mu$-ops to perform the instructions needed in
AES decryption. We discuss details of our speculative AES decryption in
Section~\ref{subsec:impl-aes}.


\subsubsection{Obfuscating keys with nested speculation}
\label{subsec:nested-spec}

As mentioned, even with encryption, an analyst that can locate the
speculative entry point and discover the decryption key. For instance, the
analyst could locate the speculative entry point by searching for AES-NI
instructions in the payload program, ultimately discovering the keys it derives
and uses.

We can overcome this by having the trigger program communicate the decryption
key to the payload program via the branch predictor. Previous work has analyzed
the capability of the branch predictor to distribute keys to other
programs~\cite{evtyushkin2016jump, lee2017inferring, aciiccmez2007predicting}
and demonstrated that this is not a secure method of key distribution. However,
the goal of using the branch predictor is not share a single secret via entry
point but rather to use multiple jumps to construct the decryption key
speculatively. To accomplish this, we use multiple speculative entry points,
each that derives a different decryption key before calling a common decryption
routine. Since the exact speculative entry point is determined by the trigger
program, an analyst cannot discover the decryption key directly from the payload
program. 

Still, an analyst could enumerate all potential entry points, testing each one
until they find one that correctly decrypts the ciphertext. In a 1~MB binary,
there are (at most) only 1~million entry points, providing just 20~bits of
security, trivial for an analyst to brute force.

To increase security, we instead use nested speculation to \emph{chain} entry
points together. Rather than derive the key from a single entry point, we have
each potential entry point perform another indirect jump that the CPU cannot
immediately resolve, forcing it to speculate while already executing
speculatively. The predicted target of that jump will also be determined by the
trigger program. Meaning that an analyst that is (somehow, possibly via oracle,
or attacks similar to~\cite{aciiccmez2007predicting}) able to determine the
location of first speculative jump is still unable to reconstruct the whole key
as future speculative jumps are determined solely by the trigger program which
the analyst does not have access to.

For example, if the trigger program makes 30 training jumps, followed by 10
additional indirect jumps, and the payload program performs the same 30 training
jumps before a stall, the CPU will predict the payload program will also perform
the next 10 jumps. Speculatively the CPU will attempt to follow each of these
jumps speculatively. 

If each jump has the potential to land in up to 1024 possible locations, this
would provide in total $1024^{10} = 2^{100}$ possible keys, or 100~bits of
security. We describe our implementation of nested speculative execution in
Section~\ref{subsec:impl-aes}, where we achieve 128~bits of security.
Figure~\ref{fig:nested-spec} demonstrates this in practice, the trigger program
running a series of training jumps followed by indirect jumps influences the
payload program to follow the same path. Any analyst attempting to follow this
path without the trigger program would need to correctly jump to each of the 10
addresses to load the correct key. The secret key created here is not a result
of a single entry point remaining secret (via the branch predictor) but rather
multiple independent jumps by the unknown trigger program providing numerous
landing points for each jump.

\FigNestedSpec


\medskip


% Could cut
%We leverage this support in Section~\ref{subsec:decryption} to
%increase the security of speculative decryption keys.
%
%There are numerous challenges for a reverse engineer to overcome to learn how a
%malicious program with this primitive works. As with previous examples, the
%malicious instructions are only executed when the correct trigger program is
%running (priming the jump table predictor \textbf{TK: word for this?}). However,
%when the to-be-executed instructions are executed the reverse engineer cannot
%locate these instructions in the ELF file, or generated source code. These
%instructions (when they even appear) seem to be generated by themselves, with no
%apparent cause. Additionally, there is no indicator that these instructions are
%encrypted as the decryption is done in the speculative world, meaning that no
%decryption (or key interaction) is done in a way visible to a reverse engineer.
%
%This method allows for arbitrary computation that is unobservable to any observer (static or dynamic). 


% 
% Argument for obfuscating keyschedule
% 
% Challenge for Rev-Engineer
%   - Find the obfuscated key schedule
%   - Find the correct trigger program

\subsection{Emulation}

To combine our encryption and arbitrary computation in an efficient way, we
implemented an emulator that gets its instructions from the speculative
decryption described previously. In the payload program, the emulated
instructions are initially encrypted under a key that will be delivered by the
trigger, as described previously. Once the trigger executes, it will cause
instructions to be decrypted and run by the emulator.

Traditional reverse engineering methods will reveal only that
emulation is being done, while the program being emulated remains encrypted.
Even when the trigger is running, only the parts of the code that execute would
be revealed to a careful analyst observing the CPU's committed state, while the
remainder of the emulated program would remain hidden.

We design a custom emulator and instruction set---SPASM (Speculative
Assembly)---that accommodates the constraints of our speculative primitive.
SPASM is a 6-bit Instruction set, where all instructions (including operand,
registers, and arguments) fit within 6-bits. This allows each step of the
speculative world to emit a single SPASM instruction to the real world for
emulation by a light-weight SPASM emulator. Using SPASM, developers can write
programs, assemble and encrypt them into a payload program. When the
associated trigger program runs, the payload will decrypt SPASM instructions in
the speculative world, and execute them one at a time.


% The assembly level abstraction that SPASM provides is still not extremely
% user friendly as it does not allow an author to write their encrypted 
% emulator payload in a high level language.  

While the custom emulator that we developed gives higher level abstraction to
an author, it still requires programs to be written in a custom assembly language. 
We note that the \speculake model is not intrinsically linked to the SPASM emulator. 
A wrapper could be implemented around other existing emulators to construct
instructions incrementally through the fixed-width channel (e.g. using 4 8-bit
reads to reveal a single 32-bit ARM instruction), allowing for encrypted
payloads to be written in higher-level languages. We also note that this
provides flexibility to the authors, allowing them to completely redefine
instructions or use a different instruction set altogether to hamper detection.
